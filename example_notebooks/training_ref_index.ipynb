{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the refractive index\n",
    "\n",
    "This notebook goes trough the main functions and objects implemented in this library. Based on a dataset containing ~4,000 entries of type (mp_id, structure, refractive index) taken from the MaterialsProject (MP). The workflow can be devided in two parts. First, the creation of a MODData object which stores the information concerning this particular dataset: the materials, the targets and optimal features. Second, a MODNetModel is trained which can later be used for predicting on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from modnet.models import MODNetModel\n",
    "from modnet.preprocessing import MODData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the dataset\n",
    "\n",
    "In this example the dataset is a dataframe saved as a pickle. But it can be any format as long as you can retreive the structures and targets (and the mpids optionally for fast featurization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4022 datapoints\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structure</th>\n",
       "      <th>ref_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mp-624234</th>\n",
       "      <td>[[0.67808954 1.32800354 5.90141888] Te, [1.500...</td>\n",
       "      <td>2.440483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-560478</th>\n",
       "      <td>[[-0.62755181  6.55361247  9.268476  ] Ba, [4....</td>\n",
       "      <td>1.790685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-556346</th>\n",
       "      <td>[[4.43332093 4.12714801 8.8721209 ] Pr, [ 1.40...</td>\n",
       "      <td>2.056131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-13676</th>\n",
       "      <td>[[-0.14481557  3.41229366  4.12618551] O, [3.2...</td>\n",
       "      <td>2.023772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-7610</th>\n",
       "      <td>[[ 0.12549448  3.01287591 -0.20434955] Li, [1....</td>\n",
       "      <td>1.745509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   structure  ref_index\n",
       "mp-624234  [[0.67808954 1.32800354 5.90141888] Te, [1.500...   2.440483\n",
       "mp-560478  [[-0.62755181  6.55361247  9.268476  ] Ba, [4....   1.790685\n",
       "mp-556346  [[4.43332093 4.12714801 8.8721209 ] Pr, [ 1.40...   2.056131\n",
       "mp-13676   [[-0.14481557  3.41229366  4.12618551] O, [3.2...   2.023772\n",
       "mp-7610    [[ 0.12549448  3.01287591 -0.20434955] Li, [1....   1.745509"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle('data/df_ref_index.pkl')\n",
    "print('{} datapoints'.format(len(df)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating a MODData instance\n",
    "\n",
    "### (a) structure, mpid, target creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded DeBreuck2020Featurizer featurizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If you use the ChemEnv tool for your research, please consider citing the following reference(s) :\n",
      "==================================================================================================\n",
      "David Waroquiers, Xavier Gonze, Gian-Marco Rignanese, Cathrin Welker-Nieuwoudt, Frank Rosowski,\n",
      "Michael Goebel, Stephan Schenk, Peter Degelmann, Rute Andre, Robert Glaum, and Geoffroy Hautier,\n",
      "\"Statistical analysis of coordination environments in oxides\",\n",
      "Chem. Mater., 2017, 29 (19), pp 8346-8360,\n",
      "DOI: 10.1021/acs.chemmater.7b02766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "md = MODData(df['structure'],df['ref_index'].values,structure_ids = df.index, target_names = ['refractive_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Featurizing the data\n",
    "The MODData has an integrated database containing the features of many materials from the MP. By enabling fast featurization they are directtly retreived from this database and not computed from the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing features, this can take time...\n",
      "INFO:root:Fast featurization on, retrieving from database...\n",
      "INFO:root:Retrieved features for 4022 out of 4022 materials\n",
      "INFO:root:Data has successfully been featurized!\n"
     ]
    }
   ],
   "source": [
    "md.featurize(fast=True,db_file='../modnet/data/feature_database.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ElementProperty|MagpieData minimum Number</th>\n",
       "      <th>ElementProperty|MagpieData maximum Number</th>\n",
       "      <th>ElementProperty|MagpieData range Number</th>\n",
       "      <th>ElementProperty|MagpieData mean Number</th>\n",
       "      <th>ElementProperty|MagpieData avg_dev Number</th>\n",
       "      <th>ElementProperty|MagpieData mode Number</th>\n",
       "      <th>ElementProperty|MagpieData minimum MendeleevNumber</th>\n",
       "      <th>ElementProperty|MagpieData maximum MendeleevNumber</th>\n",
       "      <th>ElementProperty|MagpieData range MendeleevNumber</th>\n",
       "      <th>ElementProperty|MagpieData mean MendeleevNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>OPSiteFingerprint|std_dev square pyramidal CN_5</th>\n",
       "      <th>OPSiteFingerprint|std_dev trigonal bipyramidal CN_5</th>\n",
       "      <th>OPSiteFingerprint|std_dev q2 CN_11</th>\n",
       "      <th>OPSiteFingerprint|std_dev q4 CN_11</th>\n",
       "      <th>OPSiteFingerprint|std_dev q6 CN_11</th>\n",
       "      <th>OPSiteFingerprint|std_dev L-shaped CN_2</th>\n",
       "      <th>OPSiteFingerprint|std_dev water-like CN_2</th>\n",
       "      <th>OPSiteFingerprint|std_dev bent 120 degrees CN_2</th>\n",
       "      <th>OPSiteFingerprint|std_dev hexagonal pyramidal CN_7</th>\n",
       "      <th>OPSiteFingerprint|std_dev pentagonal bipyramidal CN_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mp-624234</th>\n",
       "      <td>8.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>85.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186438</td>\n",
       "      <td>0.175091</td>\n",
       "      <td>0.021637</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>0.072313</td>\n",
       "      <td>2.280295e-01</td>\n",
       "      <td>0.355493</td>\n",
       "      <td>0.217585</td>\n",
       "      <td>0.134621</td>\n",
       "      <td>0.163703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-560478</th>\n",
       "      <td>8.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>71.062500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098554</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.029021</td>\n",
       "      <td>0.021497</td>\n",
       "      <td>0.036379</td>\n",
       "      <td>6.497400e-02</td>\n",
       "      <td>0.051046</td>\n",
       "      <td>0.253411</td>\n",
       "      <td>0.061584</td>\n",
       "      <td>0.155998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-556346</th>\n",
       "      <td>8.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>22.307692</td>\n",
       "      <td>19.810651</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>83.692308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197575</td>\n",
       "      <td>0.194990</td>\n",
       "      <td>0.048936</td>\n",
       "      <td>0.049705</td>\n",
       "      <td>0.071292</td>\n",
       "      <td>1.099133e-01</td>\n",
       "      <td>0.268237</td>\n",
       "      <td>0.282694</td>\n",
       "      <td>0.123680</td>\n",
       "      <td>0.167256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-13676</th>\n",
       "      <td>8.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>19.888889</td>\n",
       "      <td>8.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032056</td>\n",
       "      <td>0.032056</td>\n",
       "      <td>0.046716</td>\n",
       "      <td>0.024166</td>\n",
       "      <td>0.059264</td>\n",
       "      <td>1.084202e-19</td>\n",
       "      <td>0.024395</td>\n",
       "      <td>0.199876</td>\n",
       "      <td>0.057122</td>\n",
       "      <td>0.193736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-7610</th>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>54.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5059 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ElementProperty|MagpieData minimum Number  \\\n",
       "mp-624234                                        8.0   \n",
       "mp-560478                                        8.0   \n",
       "mp-556346                                        8.0   \n",
       "mp-13676                                         8.0   \n",
       "mp-7610                                          3.0   \n",
       "\n",
       "           ElementProperty|MagpieData maximum Number  \\\n",
       "mp-624234                                       82.0   \n",
       "mp-560478                                       56.0   \n",
       "mp-556346                                       59.0   \n",
       "mp-13676                                        81.0   \n",
       "mp-7610                                         20.0   \n",
       "\n",
       "           ElementProperty|MagpieData range Number  \\\n",
       "mp-624234                                     74.0   \n",
       "mp-560478                                     48.0   \n",
       "mp-556346                                     51.0   \n",
       "mp-13676                                      73.0   \n",
       "mp-7610                                       17.0   \n",
       "\n",
       "           ElementProperty|MagpieData mean Number  \\\n",
       "mp-624234                               32.000000   \n",
       "mp-560478                               16.000000   \n",
       "mp-556346                               22.307692   \n",
       "mp-13676                                21.333333   \n",
       "mp-7610                                  9.000000   \n",
       "\n",
       "           ElementProperty|MagpieData avg_dev Number  \\\n",
       "mp-624234                                  30.000000   \n",
       "mp-560478                                  10.750000   \n",
       "mp-556346                                  19.810651   \n",
       "mp-13676                                   19.888889   \n",
       "mp-7610                                     4.000000   \n",
       "\n",
       "           ElementProperty|MagpieData mode Number  \\\n",
       "mp-624234                                     8.0   \n",
       "mp-560478                                     8.0   \n",
       "mp-556346                                     8.0   \n",
       "mp-13676                                      8.0   \n",
       "mp-7610                                       8.0   \n",
       "\n",
       "           ElementProperty|MagpieData minimum MendeleevNumber  \\\n",
       "mp-624234                                               81.0    \n",
       "mp-560478                                                9.0    \n",
       "mp-556346                                               17.0    \n",
       "mp-13676                                                76.0    \n",
       "mp-7610                                                  1.0    \n",
       "\n",
       "           ElementProperty|MagpieData maximum MendeleevNumber  \\\n",
       "mp-624234                                               90.0    \n",
       "mp-560478                                               87.0    \n",
       "mp-556346                                               96.0    \n",
       "mp-13676                                                87.0    \n",
       "mp-7610                                                 87.0    \n",
       "\n",
       "           ElementProperty|MagpieData range MendeleevNumber  \\\n",
       "mp-624234                                               9.0   \n",
       "mp-560478                                              78.0   \n",
       "mp-556346                                              79.0   \n",
       "mp-13676                                               11.0   \n",
       "mp-7610                                                86.0   \n",
       "\n",
       "           ElementProperty|MagpieData mean MendeleevNumber  ...  \\\n",
       "mp-624234                                        85.875000  ...   \n",
       "mp-560478                                        71.062500  ...   \n",
       "mp-556346                                        83.692308  ...   \n",
       "mp-13676                                         84.500000  ...   \n",
       "mp-7610                                          54.375000  ...   \n",
       "\n",
       "           OPSiteFingerprint|std_dev square pyramidal CN_5  \\\n",
       "mp-624234                                         0.186438   \n",
       "mp-560478                                         0.098554   \n",
       "mp-556346                                         0.197575   \n",
       "mp-13676                                          0.032056   \n",
       "mp-7610                                           0.000000   \n",
       "\n",
       "           OPSiteFingerprint|std_dev trigonal bipyramidal CN_5  \\\n",
       "mp-624234                                           0.175091     \n",
       "mp-560478                                           0.101200     \n",
       "mp-556346                                           0.194990     \n",
       "mp-13676                                            0.032056     \n",
       "mp-7610                                             0.000000     \n",
       "\n",
       "           OPSiteFingerprint|std_dev q2 CN_11  \\\n",
       "mp-624234                            0.021637   \n",
       "mp-560478                            0.029021   \n",
       "mp-556346                            0.048936   \n",
       "mp-13676                             0.046716   \n",
       "mp-7610                              0.000000   \n",
       "\n",
       "           OPSiteFingerprint|std_dev q4 CN_11  \\\n",
       "mp-624234                            0.047200   \n",
       "mp-560478                            0.021497   \n",
       "mp-556346                            0.049705   \n",
       "mp-13676                             0.024166   \n",
       "mp-7610                              0.000000   \n",
       "\n",
       "           OPSiteFingerprint|std_dev q6 CN_11  \\\n",
       "mp-624234                            0.072313   \n",
       "mp-560478                            0.036379   \n",
       "mp-556346                            0.071292   \n",
       "mp-13676                             0.059264   \n",
       "mp-7610                              0.000000   \n",
       "\n",
       "           OPSiteFingerprint|std_dev L-shaped CN_2  \\\n",
       "mp-624234                             2.280295e-01   \n",
       "mp-560478                             6.497400e-02   \n",
       "mp-556346                             1.099133e-01   \n",
       "mp-13676                              1.084202e-19   \n",
       "mp-7610                               0.000000e+00   \n",
       "\n",
       "           OPSiteFingerprint|std_dev water-like CN_2  \\\n",
       "mp-624234                                   0.355493   \n",
       "mp-560478                                   0.051046   \n",
       "mp-556346                                   0.268237   \n",
       "mp-13676                                    0.024395   \n",
       "mp-7610                                     0.000000   \n",
       "\n",
       "           OPSiteFingerprint|std_dev bent 120 degrees CN_2  \\\n",
       "mp-624234                                         0.217585   \n",
       "mp-560478                                         0.253411   \n",
       "mp-556346                                         0.282694   \n",
       "mp-13676                                          0.199876   \n",
       "mp-7610                                           0.000000   \n",
       "\n",
       "           OPSiteFingerprint|std_dev hexagonal pyramidal CN_7  \\\n",
       "mp-624234                                           0.134621    \n",
       "mp-560478                                           0.061584    \n",
       "mp-556346                                           0.123680    \n",
       "mp-13676                                            0.057122    \n",
       "mp-7610                                             0.000000    \n",
       "\n",
       "           OPSiteFingerprint|std_dev pentagonal bipyramidal CN_7  \n",
       "mp-624234                                           0.163703      \n",
       "mp-560478                                           0.155998      \n",
       "mp-556346                                           0.167256      \n",
       "mp-13676                                            0.193736      \n",
       "mp-7610                                             0.000000      \n",
       "\n",
       "[5 rows x 5059 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.get_featurized_df().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Computing the optimal features\n",
    "\n",
    "This runs the feature selction algorithm. First the multual information is computed, followed by the iterative selction based on relevance and redundancy.\n",
    "\n",
    "This step takes time, but is normally run only once before being saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading cross NMI from 'Features_cross' file.\n",
      "INFO:root:Starting target 1/1: refractive_index ...\n",
      "INFO:root:Computing mutual information between features and target...\n",
      "INFO:root:Computing optimal features...\n",
      "INFO:root:Selected 50/1019 features...\n",
      "INFO:root:Selected 100/1019 features...\n",
      "INFO:root:Selected 150/1019 features...\n",
      "INFO:root:Selected 200/1019 features...\n",
      "INFO:root:Selected 250/1019 features...\n",
      "INFO:root:Selected 300/1019 features...\n",
      "INFO:root:Selected 350/1019 features...\n",
      "INFO:root:Selected 400/1019 features...\n",
      "INFO:root:Selected 450/1019 features...\n",
      "INFO:root:Selected 500/1019 features...\n",
      "INFO:root:Selected 550/1019 features...\n",
      "INFO:root:Selected 600/1019 features...\n",
      "INFO:root:Selected 650/1019 features...\n",
      "INFO:root:Selected 700/1019 features...\n",
      "INFO:root:Selected 750/1019 features...\n",
      "INFO:root:Selected 800/1019 features...\n",
      "INFO:root:Selected 850/1019 features...\n",
      "INFO:root:Selected 900/1019 features...\n",
      "INFO:root:Selected 950/1019 features...\n",
      "INFO:root:Selected 1000/1019 features...\n",
      "INFO:root:Done with target 1/4022: refractive_index.\n",
      "INFO:root:Merging all features...\n",
      "INFO:root:Done.\n"
     ]
    }
   ],
   "source": [
    "md.feature_selection(n=1100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ElementProperty|MagpieData maximum GSbandgap',\n",
       " 'ElementFraction|Th',\n",
       " 'CrystalNNFingerprint|std_dev hexagonal bipyramidal CN_8',\n",
       " 'DensityFeatures|density',\n",
       " 'ElementProperty|MagpieData avg_dev Number',\n",
       " 'LocalPropertyDifference|mean local difference in Electronegativity',\n",
       " 'BondOrientationParameter|mean BOOP Q l=2',\n",
       " 'ElementProperty|MagpieData range NdValence',\n",
       " 'DensityFeatures|packing fraction',\n",
       " 'OPSiteFingerprint|mean sgl_bd CN_1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.get_optimal_descriptors()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Saving the MODData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Data successfully saved as out/md_ref_index!\n"
     ]
    }
   ],
   "source": [
    "md.save('out/md_ref_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MODNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded <modnet.preprocessing.MODData object at 0x7fe2c411a8b0> object, created with modnet version 0.1.8\n"
     ]
    }
   ],
   "source": [
    "md = MODData.load('out/md_ref_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Creating the MODNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1000)]            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               128128    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "refractive_index (Dense)     (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 138,497\n",
      "Trainable params: 138,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MODNetModel([[['refractive_index']]],{'refractive_index':1},n_feat=1000, num_neurons=[[128],[64],[32],[]], act='elu')\n",
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "41/57 [====================>.........] - ETA: 0s - loss: 0.2901 - mae: 0.2901epoch 0: loss: 0.258, val_loss:0.144 val_mae:0.144\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2584 - mae: 0.2584 - val_loss: 0.1436 - val_mae: 0.1436\n",
      "Epoch 2/300\n",
      "41/57 [====================>.........] - ETA: 0s - loss: 0.1382 - mae: 0.1382epoch 1: loss: 0.138, val_loss:0.126 val_mae:0.126\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1385 - mae: 0.1385 - val_loss: 0.1257 - val_mae: 0.1257\n",
      "Epoch 3/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.1225 - mae: 0.1225epoch 2: loss: 0.124, val_loss:0.124 val_mae:0.124\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.1241 - mae: 0.1241 - val_loss: 0.1244 - val_mae: 0.1244\n",
      "Epoch 4/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.1173 - mae: 0.1173epoch 3: loss: 0.116, val_loss:0.104 val_mae:0.104\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.1155 - mae: 0.1155 - val_loss: 0.1041 - val_mae: 0.1041\n",
      "Epoch 5/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.1090 - mae: 0.1090epoch 4: loss: 0.108, val_loss:0.106 val_mae:0.106\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.1082 - mae: 0.1082 - val_loss: 0.1062 - val_mae: 0.1062\n",
      "Epoch 6/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0984 - mae: 0.0984epoch 5: loss: 0.096, val_loss:0.100 val_mae:0.100\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0960 - mae: 0.0960 - val_loss: 0.1002 - val_mae: 0.1002\n",
      "Epoch 7/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.1052 - mae: 0.1052epoch 6: loss: 0.105, val_loss:0.096 val_mae:0.096\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1055 - mae: 0.1055 - val_loss: 0.0959 - val_mae: 0.0959\n",
      "Epoch 8/300\n",
      "47/57 [=======================>......] - ETA: 0s - loss: 0.0948 - mae: 0.0948epoch 7: loss: 0.094, val_loss:0.114 val_mae:0.114\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0941 - mae: 0.0941 - val_loss: 0.1140 - val_mae: 0.1140\n",
      "Epoch 9/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0912 - mae: 0.0912epoch 8: loss: 0.093, val_loss:0.088 val_mae:0.088\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0935 - mae: 0.0935 - val_loss: 0.0882 - val_mae: 0.0882\n",
      "Epoch 10/300\n",
      "48/57 [========================>.....] - ETA: 0s - loss: 0.0822 - mae: 0.0822epoch 9: loss: 0.084, val_loss:0.102 val_mae:0.102\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0838 - mae: 0.0838 - val_loss: 0.1018 - val_mae: 0.1018\n",
      "Epoch 11/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0823 - mae: 0.0823epoch 10: loss: 0.082, val_loss:0.084 val_mae:0.084\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0821 - mae: 0.0821 - val_loss: 0.0837 - val_mae: 0.0837\n",
      "Epoch 12/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0831 - mae: 0.0831epoch 11: loss: 0.082, val_loss:0.083 val_mae:0.083\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0816 - mae: 0.0816 - val_loss: 0.0826 - val_mae: 0.0826\n",
      "Epoch 13/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0724 - mae: 0.0724epoch 12: loss: 0.076, val_loss:0.152 val_mae:0.152\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0755 - mae: 0.0755 - val_loss: 0.1517 - val_mae: 0.1517\n",
      "Epoch 14/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0924 - mae: 0.0924epoch 13: loss: 0.090, val_loss:0.089 val_mae:0.089\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0896 - mae: 0.0896 - val_loss: 0.0892 - val_mae: 0.0892\n",
      "Epoch 15/300\n",
      "50/57 [=========================>....] - ETA: 0s - loss: 0.0756 - mae: 0.0756epoch 14: loss: 0.076, val_loss:0.090 val_mae:0.090\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0761 - mae: 0.0761 - val_loss: 0.0896 - val_mae: 0.0896\n",
      "Epoch 16/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0742 - mae: 0.0742epoch 15: loss: 0.074, val_loss:0.089 val_mae:0.089\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0744 - mae: 0.0744 - val_loss: 0.0891 - val_mae: 0.0891\n",
      "Epoch 17/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0776 - mae: 0.0776epoch 16: loss: 0.077, val_loss:0.087 val_mae:0.087\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0773 - mae: 0.0773 - val_loss: 0.0869 - val_mae: 0.0869\n",
      "Epoch 18/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0727 - mae: 0.0727epoch 17: loss: 0.073, val_loss:0.074 val_mae:0.074\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0732 - mae: 0.0732 - val_loss: 0.0735 - val_mae: 0.0735\n",
      "Epoch 19/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0684 - mae: 0.0684epoch 18: loss: 0.072, val_loss:0.131 val_mae:0.131\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0723 - mae: 0.0723 - val_loss: 0.1312 - val_mae: 0.1312\n",
      "Epoch 20/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0957 - mae: 0.0957epoch 19: loss: 0.087, val_loss:0.077 val_mae:0.077\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0874 - mae: 0.0874 - val_loss: 0.0769 - val_mae: 0.0769\n",
      "Epoch 21/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0666 - mae: 0.0666epoch 20: loss: 0.066, val_loss:0.083 val_mae:0.083\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0665 - mae: 0.0665 - val_loss: 0.0829 - val_mae: 0.0829\n",
      "Epoch 22/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0705 - mae: 0.0705epoch 21: loss: 0.070, val_loss:0.077 val_mae:0.077\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0703 - mae: 0.0703 - val_loss: 0.0769 - val_mae: 0.0769\n",
      "Epoch 23/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0709 - mae: 0.0709epoch 22: loss: 0.074, val_loss:0.083 val_mae:0.083\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0739 - mae: 0.0739 - val_loss: 0.0830 - val_mae: 0.0830\n",
      "Epoch 24/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0715 - mae: 0.0715epoch 23: loss: 0.069, val_loss:0.072 val_mae:0.072\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0688 - mae: 0.0688 - val_loss: 0.0718 - val_mae: 0.0718\n",
      "Epoch 25/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0630 - mae: 0.0630epoch 24: loss: 0.065, val_loss:0.079 val_mae:0.079\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0649 - mae: 0.0649 - val_loss: 0.0794 - val_mae: 0.0794\n",
      "Epoch 26/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0646 - mae: 0.0646epoch 25: loss: 0.067, val_loss:0.078 val_mae:0.078\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0666 - mae: 0.0666 - val_loss: 0.0777 - val_mae: 0.0777\n",
      "Epoch 27/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0628 - mae: 0.0628epoch 26: loss: 0.065, val_loss:0.105 val_mae:0.105\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0646 - mae: 0.0646 - val_loss: 0.1047 - val_mae: 0.1047\n",
      "Epoch 28/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0690 - mae: 0.0690epoch 27: loss: 0.067, val_loss:0.075 val_mae:0.075\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0671 - mae: 0.0671 - val_loss: 0.0746 - val_mae: 0.0746\n",
      "Epoch 29/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0616 - mae: 0.0616epoch 28: loss: 0.061, val_loss:0.073 val_mae:0.073\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0608 - mae: 0.0608 - val_loss: 0.0734 - val_mae: 0.0734\n",
      "Epoch 30/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0627 - mae: 0.0627epoch 29: loss: 0.064, val_loss:0.082 val_mae:0.082\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0643 - mae: 0.0643 - val_loss: 0.0821 - val_mae: 0.0821\n",
      "Epoch 31/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0780 - mae: 0.0780epoch 30: loss: 0.076, val_loss:0.068 val_mae:0.068\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0756 - mae: 0.0756 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 32/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0606 - mae: 0.0606epoch 31: loss: 0.059, val_loss:0.069 val_mae:0.069\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0590 - mae: 0.0590 - val_loss: 0.0691 - val_mae: 0.0691\n",
      "Epoch 33/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0580 - mae: 0.0580epoch 32: loss: 0.058, val_loss:0.074 val_mae:0.074\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0581 - mae: 0.0581 - val_loss: 0.0738 - val_mae: 0.0738\n",
      "Epoch 34/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0558 - mae: 0.0558epoch 33: loss: 0.059, val_loss:0.069 val_mae:0.069\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0588 - mae: 0.0588 - val_loss: 0.0687 - val_mae: 0.0687\n",
      "Epoch 35/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0676 - mae: 0.0676epoch 34: loss: 0.065, val_loss:0.072 val_mae:0.072\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0651 - mae: 0.0651 - val_loss: 0.0721 - val_mae: 0.0721\n",
      "Epoch 36/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0532 - mae: 0.0532epoch 35: loss: 0.056, val_loss:0.076 val_mae:0.076\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0555 - mae: 0.0555 - val_loss: 0.0762 - val_mae: 0.0762\n",
      "Epoch 37/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0598 - mae: 0.0598epoch 36: loss: 0.060, val_loss:0.067 val_mae:0.067\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0598 - mae: 0.0598 - val_loss: 0.0668 - val_mae: 0.0668\n",
      "Epoch 38/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0599 - mae: 0.0599epoch 37: loss: 0.058, val_loss:0.061 val_mae:0.061\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0580 - mae: 0.0580 - val_loss: 0.0614 - val_mae: 0.0614\n",
      "Epoch 39/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0571 - mae: 0.0571epoch 38: loss: 0.063, val_loss:0.067 val_mae:0.067\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0626 - mae: 0.0626 - val_loss: 0.0673 - val_mae: 0.0673\n",
      "Epoch 40/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0588 - mae: 0.0588epoch 39: loss: 0.058, val_loss:0.082 val_mae:0.082\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0579 - mae: 0.0579 - val_loss: 0.0817 - val_mae: 0.0817\n",
      "Epoch 41/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0612 - mae: 0.0612epoch 40: loss: 0.061, val_loss:0.072 val_mae:0.072\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0614 - mae: 0.0614 - val_loss: 0.0722 - val_mae: 0.0722\n",
      "Epoch 42/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0605 - mae: 0.0605epoch 41: loss: 0.061, val_loss:0.072 val_mae:0.072\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0607 - mae: 0.0607 - val_loss: 0.0724 - val_mae: 0.0724\n",
      "Epoch 43/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0588 - mae: 0.0588epoch 42: loss: 0.059, val_loss:0.080 val_mae:0.080\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0594 - mae: 0.0594 - val_loss: 0.0796 - val_mae: 0.0796\n",
      "Epoch 44/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0520 - mae: 0.0520epoch 43: loss: 0.052, val_loss:0.073 val_mae:0.073\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0524 - mae: 0.0524 - val_loss: 0.0734 - val_mae: 0.0734\n",
      "Epoch 45/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0559 - mae: 0.0559epoch 44: loss: 0.055, val_loss:0.082 val_mae:0.082\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0551 - mae: 0.0551 - val_loss: 0.0818 - val_mae: 0.0818\n",
      "Epoch 46/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0608 - mae: 0.0608epoch 45: loss: 0.058, val_loss:0.068 val_mae:0.068\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0578 - mae: 0.0578 - val_loss: 0.0679 - val_mae: 0.0679\n",
      "Epoch 47/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0536 - mae: 0.0536epoch 46: loss: 0.053, val_loss:0.068 val_mae:0.068\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0530 - mae: 0.0530 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 48/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0559 - mae: 0.0559epoch 47: loss: 0.056, val_loss:0.079 val_mae:0.079\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0562 - mae: 0.0562 - val_loss: 0.0790 - val_mae: 0.0790\n",
      "Epoch 49/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0563 - mae: 0.0563epoch 48: loss: 0.057, val_loss:0.079 val_mae:0.079\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0567 - mae: 0.0567 - val_loss: 0.0793 - val_mae: 0.0793\n",
      "Epoch 50/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0634 - mae: 0.0634epoch 49: loss: 0.060, val_loss:0.063 val_mae:0.063\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0603 - mae: 0.0603 - val_loss: 0.0631 - val_mae: 0.0631\n",
      "Epoch 51/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0510 - mae: 0.0510epoch 50: loss: 0.052, val_loss:0.066 val_mae:0.066\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0517 - mae: 0.0517 - val_loss: 0.0658 - val_mae: 0.0658\n",
      "Epoch 52/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0584 - mae: 0.0584epoch 51: loss: 0.056, val_loss:0.064 val_mae:0.064\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0563 - mae: 0.0563 - val_loss: 0.0635 - val_mae: 0.0635\n",
      "Epoch 53/300\n",
      "47/57 [=======================>......] - ETA: 0s - loss: 0.0491 - mae: 0.0491epoch 52: loss: 0.048, val_loss:0.063 val_mae:0.063\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0483 - mae: 0.0483 - val_loss: 0.0631 - val_mae: 0.0631\n",
      "Epoch 54/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0462 - mae: 0.0462epoch 53: loss: 0.047, val_loss:0.061 val_mae:0.061\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0469 - mae: 0.0469 - val_loss: 0.0612 - val_mae: 0.0612\n",
      "Epoch 55/300\n",
      "48/57 [========================>.....] - ETA: 0s - loss: 0.0443 - mae: 0.0443epoch 54: loss: 0.045, val_loss:0.062 val_mae:0.062\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0452 - mae: 0.0452 - val_loss: 0.0624 - val_mae: 0.0624\n",
      "Epoch 56/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0461 - mae: 0.0461epoch 55: loss: 0.047, val_loss:0.065 val_mae:0.065\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0468 - mae: 0.0468 - val_loss: 0.0651 - val_mae: 0.0651\n",
      "Epoch 57/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0539 - mae: 0.0539epoch 56: loss: 0.055, val_loss:0.071 val_mae:0.071\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0548 - mae: 0.0548 - val_loss: 0.0712 - val_mae: 0.0712\n",
      "Epoch 58/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0504 - mae: 0.0504epoch 57: loss: 0.049, val_loss:0.069 val_mae:0.069\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0493 - mae: 0.0493 - val_loss: 0.0685 - val_mae: 0.0685\n",
      "Epoch 59/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0467 - mae: 0.0467epoch 58: loss: 0.047, val_loss:0.061 val_mae:0.061\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0467 - mae: 0.0467 - val_loss: 0.0605 - val_mae: 0.0605\n",
      "Epoch 60/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0485 - mae: 0.0485epoch 59: loss: 0.052, val_loss:0.061 val_mae:0.061\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0522 - mae: 0.0522 - val_loss: 0.0608 - val_mae: 0.0608\n",
      "Epoch 61/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0548 - mae: 0.0548epoch 60: loss: 0.059, val_loss:0.071 val_mae:0.071\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0592 - mae: 0.0592 - val_loss: 0.0707 - val_mae: 0.0707\n",
      "Epoch 62/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0561 - mae: 0.0561epoch 61: loss: 0.056, val_loss:0.069 val_mae:0.069\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0555 - mae: 0.0555 - val_loss: 0.0690 - val_mae: 0.0690\n",
      "Epoch 63/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0452 - mae: 0.0452epoch 62: loss: 0.046, val_loss:0.070 val_mae:0.070\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0458 - mae: 0.0458 - val_loss: 0.0697 - val_mae: 0.0697\n",
      "Epoch 64/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0605 - mae: 0.0605epoch 63: loss: 0.058, val_loss:0.065 val_mae:0.065\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0577 - mae: 0.0577 - val_loss: 0.0650 - val_mae: 0.0650\n",
      "Epoch 65/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0479 - mae: 0.0479epoch 64: loss: 0.047, val_loss:0.065 val_mae:0.065\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0475 - mae: 0.0475 - val_loss: 0.0653 - val_mae: 0.0653\n",
      "Epoch 66/300\n",
      "47/57 [=======================>......] - ETA: 0s - loss: 0.0491 - mae: 0.0491epoch 65: loss: 0.049, val_loss:0.062 val_mae:0.062\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0486 - mae: 0.0486 - val_loss: 0.0620 - val_mae: 0.0620\n",
      "Epoch 67/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0450 - mae: 0.0450epoch 66: loss: 0.046, val_loss:0.072 val_mae:0.072\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0456 - mae: 0.0456 - val_loss: 0.0719 - val_mae: 0.0719\n",
      "Epoch 68/300\n",
      "37/57 [==================>...........] - ETA: 0s - loss: 0.0494 - mae: 0.0494epoch 67: loss: 0.046, val_loss:0.062 val_mae:0.062\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0458 - mae: 0.0458 - val_loss: 0.0617 - val_mae: 0.0617\n",
      "Epoch 69/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0470 - mae: 0.0470epoch 68: loss: 0.046, val_loss:0.060 val_mae:0.060\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0460 - mae: 0.0460 - val_loss: 0.0598 - val_mae: 0.0598\n",
      "Epoch 70/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0472 - mae: 0.0472epoch 69: loss: 0.047, val_loss:0.065 val_mae:0.065\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0473 - mae: 0.0473 - val_loss: 0.0647 - val_mae: 0.0647\n",
      "Epoch 71/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0425 - mae: 0.0425epoch 70: loss: 0.046, val_loss:0.069 val_mae:0.069\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0461 - mae: 0.0461 - val_loss: 0.0693 - val_mae: 0.0693\n",
      "Epoch 72/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0465 - mae: 0.0465epoch 71: loss: 0.046, val_loss:0.063 val_mae:0.063\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0463 - mae: 0.0463 - val_loss: 0.0631 - val_mae: 0.0631\n",
      "Epoch 73/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0443 - mae: 0.0443epoch 72: loss: 0.045, val_loss:0.071 val_mae:0.071\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0455 - mae: 0.0455 - val_loss: 0.0710 - val_mae: 0.0710\n",
      "Epoch 74/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0450 - mae: 0.0450epoch 73: loss: 0.045, val_loss:0.064 val_mae:0.064\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0446 - mae: 0.0446 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 75/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0545 - mae: 0.0545epoch 74: loss: 0.052, val_loss:0.061 val_mae:0.061\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0521 - mae: 0.0521 - val_loss: 0.0607 - val_mae: 0.0607\n",
      "Epoch 76/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0439 - mae: 0.0439epoch 75: loss: 0.044, val_loss:0.061 val_mae:0.061\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0437 - mae: 0.0437 - val_loss: 0.0610 - val_mae: 0.0610\n",
      "Epoch 77/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0402 - mae: 0.0402epoch 76: loss: 0.040, val_loss:0.062 val_mae:0.062\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0397 - mae: 0.0397 - val_loss: 0.0617 - val_mae: 0.0617\n",
      "Epoch 78/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0440 - mae: 0.0440epoch 77: loss: 0.044, val_loss:0.064 val_mae:0.064\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0443 - mae: 0.0443 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 79/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0415 - mae: 0.0415epoch 78: loss: 0.044, val_loss:0.058 val_mae:0.058\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0436 - mae: 0.0436 - val_loss: 0.0575 - val_mae: 0.0575\n",
      "Epoch 80/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0478 - mae: 0.0478epoch 79: loss: 0.047, val_loss:0.070 val_mae:0.070\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0470 - mae: 0.0470 - val_loss: 0.0704 - val_mae: 0.0704\n",
      "Epoch 81/300\n",
      "47/57 [=======================>......] - ETA: 0s - loss: 0.0417 - mae: 0.0417epoch 80: loss: 0.041, val_loss:0.066 val_mae:0.066\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0412 - mae: 0.0412 - val_loss: 0.0657 - val_mae: 0.0657\n",
      "Epoch 82/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0425 - mae: 0.0425epoch 81: loss: 0.045, val_loss:0.068 val_mae:0.068\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0447 - mae: 0.0447 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 83/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0476 - mae: 0.0476epoch 82: loss: 0.046, val_loss:0.058 val_mae:0.058\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0456 - mae: 0.0456 - val_loss: 0.0579 - val_mae: 0.0579\n",
      "Epoch 84/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0449 - mae: 0.0449epoch 83: loss: 0.045, val_loss:0.067 val_mae:0.067\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0450 - mae: 0.0450 - val_loss: 0.0666 - val_mae: 0.0666\n",
      "Epoch 85/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0445 - mae: 0.0445epoch 84: loss: 0.045, val_loss:0.060 val_mae:0.060\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0452 - mae: 0.0452 - val_loss: 0.0601 - val_mae: 0.0601\n",
      "Epoch 86/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0447 - mae: 0.0447epoch 85: loss: 0.043, val_loss:0.058 val_mae:0.058\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0433 - mae: 0.0433 - val_loss: 0.0581 - val_mae: 0.0581\n",
      "Epoch 87/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0409 - mae: 0.0409epoch 86: loss: 0.042, val_loss:0.067 val_mae:0.067\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0416 - mae: 0.0416 - val_loss: 0.0667 - val_mae: 0.0667\n",
      "Epoch 88/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0437 - mae: 0.0437epoch 87: loss: 0.042, val_loss:0.058 val_mae:0.058\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0424 - mae: 0.0424 - val_loss: 0.0582 - val_mae: 0.0582\n",
      "Epoch 89/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0390 - mae: 0.0390epoch 88: loss: 0.039, val_loss:0.066 val_mae:0.066\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0394 - mae: 0.0394 - val_loss: 0.0663 - val_mae: 0.0663\n",
      "Epoch 90/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0520 - mae: 0.0520epoch 89: loss: 0.050, val_loss:0.064 val_mae:0.064\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0501 - mae: 0.0501 - val_loss: 0.0645 - val_mae: 0.0645\n",
      "Epoch 91/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0440 - mae: 0.0440epoch 90: loss: 0.044, val_loss:0.079 val_mae:0.079\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0439 - mae: 0.0439 - val_loss: 0.0790 - val_mae: 0.0790\n",
      "Epoch 92/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0467 - mae: 0.0467epoch 91: loss: 0.045, val_loss:0.060 val_mae:0.060\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0449 - mae: 0.0449 - val_loss: 0.0595 - val_mae: 0.0595\n",
      "Epoch 93/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0394 - mae: 0.0394epoch 92: loss: 0.039, val_loss:0.060 val_mae:0.060\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0391 - mae: 0.0391 - val_loss: 0.0604 - val_mae: 0.0604\n",
      "Epoch 94/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0409 - mae: 0.0409epoch 93: loss: 0.043, val_loss:0.078 val_mae:0.078\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0430 - mae: 0.0430 - val_loss: 0.0783 - val_mae: 0.0783\n",
      "Epoch 95/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0469 - mae: 0.0469epoch 94: loss: 0.045, val_loss:0.060 val_mae:0.060\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0455 - mae: 0.0455 - val_loss: 0.0601 - val_mae: 0.0601\n",
      "Epoch 96/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0440 - mae: 0.0440epoch 95: loss: 0.043, val_loss:0.073 val_mae:0.073\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0426 - mae: 0.0426 - val_loss: 0.0732 - val_mae: 0.0732\n",
      "Epoch 97/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0391 - mae: 0.0391epoch 96: loss: 0.041, val_loss:0.057 val_mae:0.057\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0408 - mae: 0.0408 - val_loss: 0.0574 - val_mae: 0.0574\n",
      "Epoch 98/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0391 - mae: 0.0391epoch 97: loss: 0.039, val_loss:0.071 val_mae:0.071\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0392 - mae: 0.0392 - val_loss: 0.0712 - val_mae: 0.0712\n",
      "Epoch 99/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0401 - mae: 0.0401epoch 98: loss: 0.039, val_loss:0.061 val_mae:0.061\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0392 - mae: 0.0392 - val_loss: 0.0610 - val_mae: 0.0610\n",
      "Epoch 100/300\n",
      "48/57 [========================>.....] - ETA: 0s - loss: 0.0362 - mae: 0.0362epoch 99: loss: 0.036, val_loss:0.062 val_mae:0.062\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0362 - mae: 0.0362 - val_loss: 0.0623 - val_mae: 0.0623\n",
      "Epoch 101/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0339 - mae: 0.0339epoch 100: loss: 0.035, val_loss:0.061 val_mae:0.061\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0350 - mae: 0.0350 - val_loss: 0.0611 - val_mae: 0.0611\n",
      "Epoch 102/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0347 - mae: 0.0347epoch 101: loss: 0.035, val_loss:0.063 val_mae:0.063\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0352 - mae: 0.0352 - val_loss: 0.0627 - val_mae: 0.0627\n",
      "Epoch 103/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0387 - mae: 0.0387epoch 102: loss: 0.039, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0389 - mae: 0.0389 - val_loss: 0.0587 - val_mae: 0.0587\n",
      "Epoch 104/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0375 - mae: 0.0375epoch 103: loss: 0.039, val_loss:0.062 val_mae:0.062\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0392 - mae: 0.0392 - val_loss: 0.0624 - val_mae: 0.0624\n",
      "Epoch 105/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0367 - mae: 0.0367epoch 104: loss: 0.038, val_loss:0.057 val_mae:0.057\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0381 - mae: 0.0381 - val_loss: 0.0573 - val_mae: 0.0573\n",
      "Epoch 106/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0504 - mae: 0.0504epoch 105: loss: 0.047, val_loss:0.060 val_mae:0.060\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0470 - mae: 0.0470 - val_loss: 0.0600 - val_mae: 0.0600\n",
      "Epoch 107/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0389 - mae: 0.0389epoch 106: loss: 0.038, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0383 - mae: 0.0383 - val_loss: 0.0550 - val_mae: 0.0550\n",
      "Epoch 108/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0335 - mae: 0.0335epoch 107: loss: 0.034, val_loss:0.070 val_mae:0.070\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0342 - mae: 0.0342 - val_loss: 0.0697 - val_mae: 0.0697\n",
      "Epoch 109/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0354 - mae: 0.0354epoch 108: loss: 0.036, val_loss:0.056 val_mae:0.056\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0362 - mae: 0.0362 - val_loss: 0.0558 - val_mae: 0.0558\n",
      "Epoch 110/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0371 - mae: 0.0371epoch 109: loss: 0.037, val_loss:0.057 val_mae:0.057\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0369 - mae: 0.0369 - val_loss: 0.0572 - val_mae: 0.0572\n",
      "Epoch 111/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0366 - mae: 0.0366epoch 110: loss: 0.036, val_loss:0.063 val_mae:0.063\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0363 - mae: 0.0363 - val_loss: 0.0629 - val_mae: 0.0629\n",
      "Epoch 112/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0403 - mae: 0.0403epoch 111: loss: 0.039, val_loss:0.058 val_mae:0.058\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0390 - mae: 0.0390 - val_loss: 0.0579 - val_mae: 0.0579\n",
      "Epoch 113/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0382 - mae: 0.0382epoch 112: loss: 0.037, val_loss:0.057 val_mae:0.057\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0368 - mae: 0.0368 - val_loss: 0.0566 - val_mae: 0.0566\n",
      "Epoch 114/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0372 - mae: 0.0372epoch 113: loss: 0.038, val_loss:0.060 val_mae:0.060\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0377 - mae: 0.0377 - val_loss: 0.0601 - val_mae: 0.0601\n",
      "Epoch 115/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0330 - mae: 0.0330epoch 114: loss: 0.034, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0342 - mae: 0.0342 - val_loss: 0.0551 - val_mae: 0.0551\n",
      "Epoch 116/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0362 - mae: 0.0362epoch 115: loss: 0.036, val_loss:0.061 val_mae:0.061\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0360 - mae: 0.0360 - val_loss: 0.0606 - val_mae: 0.0606\n",
      "Epoch 117/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0358 - mae: 0.0358epoch 116: loss: 0.038, val_loss:0.064 val_mae:0.064\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0376 - mae: 0.0376 - val_loss: 0.0639 - val_mae: 0.0639\n",
      "Epoch 118/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0386 - mae: 0.0386epoch 117: loss: 0.039, val_loss:0.063 val_mae:0.063\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0391 - mae: 0.0391 - val_loss: 0.0629 - val_mae: 0.0629\n",
      "Epoch 119/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0421 - mae: 0.0421epoch 118: loss: 0.042, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0416 - mae: 0.0416 - val_loss: 0.0585 - val_mae: 0.0585\n",
      "Epoch 120/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0388 - mae: 0.0388epoch 119: loss: 0.038, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0378 - mae: 0.0378 - val_loss: 0.0591 - val_mae: 0.0591\n",
      "Epoch 121/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0351 - mae: 0.0351epoch 120: loss: 0.035, val_loss:0.061 val_mae:0.061\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0348 - mae: 0.0348 - val_loss: 0.0612 - val_mae: 0.0612\n",
      "Epoch 122/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0465 - mae: 0.0465epoch 121: loss: 0.045, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0449 - mae: 0.0449 - val_loss: 0.0588 - val_mae: 0.0588\n",
      "Epoch 123/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0346 - mae: 0.0346epoch 122: loss: 0.034, val_loss:0.056 val_mae:0.056\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0340 - mae: 0.0340 - val_loss: 0.0557 - val_mae: 0.0557\n",
      "Epoch 124/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0331 - mae: 0.0331epoch 123: loss: 0.034, val_loss:0.073 val_mae:0.073\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0336 - mae: 0.0336 - val_loss: 0.0729 - val_mae: 0.0729\n",
      "Epoch 125/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0324 - mae: 0.0324epoch 124: loss: 0.034, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0337 - mae: 0.0337 - val_loss: 0.0588 - val_mae: 0.0588\n",
      "Epoch 126/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0319 - mae: 0.0319epoch 125: loss: 0.035, val_loss:0.070 val_mae:0.070\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0346 - mae: 0.0346 - val_loss: 0.0699 - val_mae: 0.0699\n",
      "Epoch 127/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0357 - mae: 0.0357epoch 126: loss: 0.037, val_loss:0.062 val_mae:0.062\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0369 - mae: 0.0369 - val_loss: 0.0618 - val_mae: 0.0618\n",
      "Epoch 128/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0323 - mae: 0.0323epoch 127: loss: 0.032, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0318 - mae: 0.0318 - val_loss: 0.0595 - val_mae: 0.0595\n",
      "Epoch 129/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0429 - mae: 0.0429epoch 128: loss: 0.042, val_loss:0.065 val_mae:0.065\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0424 - mae: 0.0424 - val_loss: 0.0648 - val_mae: 0.0648\n",
      "Epoch 130/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0385 - mae: 0.0385epoch 129: loss: 0.039, val_loss:0.067 val_mae:0.067\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0394 - mae: 0.0394 - val_loss: 0.0670 - val_mae: 0.0670\n",
      "Epoch 131/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0357 - mae: 0.0357epoch 130: loss: 0.035, val_loss:0.056 val_mae:0.056\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0352 - mae: 0.0352 - val_loss: 0.0559 - val_mae: 0.0559\n",
      "Epoch 132/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0335 - mae: 0.0335epoch 131: loss: 0.034, val_loss:0.063 val_mae:0.063\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0340 - mae: 0.0340 - val_loss: 0.0628 - val_mae: 0.0628\n",
      "Epoch 133/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0321 - mae: 0.0321epoch 132: loss: 0.033, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0329 - mae: 0.0329 - val_loss: 0.0592 - val_mae: 0.0592\n",
      "Epoch 134/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0344 - mae: 0.0344epoch 133: loss: 0.034, val_loss:0.060 val_mae:0.060\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0336 - mae: 0.0336 - val_loss: 0.0601 - val_mae: 0.0601\n",
      "Epoch 135/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0342 - mae: 0.0342epoch 134: loss: 0.034, val_loss:0.062 val_mae:0.062\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0341 - mae: 0.0341 - val_loss: 0.0621 - val_mae: 0.0621\n",
      "Epoch 136/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0345 - mae: 0.0345epoch 135: loss: 0.034, val_loss:0.058 val_mae:0.058\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0340 - mae: 0.0340 - val_loss: 0.0578 - val_mae: 0.0578\n",
      "Epoch 137/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0336 - mae: 0.0336epoch 136: loss: 0.035, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0354 - mae: 0.0354 - val_loss: 0.0589 - val_mae: 0.0589\n",
      "Epoch 138/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0395 - mae: 0.0395epoch 137: loss: 0.038, val_loss:0.064 val_mae:0.064\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0383 - mae: 0.0383 - val_loss: 0.0641 - val_mae: 0.0641\n",
      "Epoch 139/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0399 - mae: 0.0399epoch 138: loss: 0.038, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0382 - mae: 0.0382 - val_loss: 0.0548 - val_mae: 0.0548\n",
      "Epoch 140/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0308 - mae: 0.0308epoch 139: loss: 0.032, val_loss:0.057 val_mae:0.057\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0322 - mae: 0.0322 - val_loss: 0.0574 - val_mae: 0.0574\n",
      "Epoch 141/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0432 - mae: 0.0432epoch 140: loss: 0.044, val_loss:0.067 val_mae:0.067\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0440 - mae: 0.0440 - val_loss: 0.0665 - val_mae: 0.0665\n",
      "Epoch 142/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0409 - mae: 0.0409epoch 141: loss: 0.039, val_loss:0.056 val_mae:0.056\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0390 - mae: 0.0390 - val_loss: 0.0564 - val_mae: 0.0564\n",
      "Epoch 143/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0314 - mae: 0.0314epoch 142: loss: 0.030, val_loss:0.063 val_mae:0.063\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0303 - mae: 0.0303 - val_loss: 0.0630 - val_mae: 0.0630\n",
      "Epoch 144/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0322 - mae: 0.0322epoch 143: loss: 0.031, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0314 - mae: 0.0314 - val_loss: 0.0548 - val_mae: 0.0548\n",
      "Epoch 145/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0306 - mae: 0.0306epoch 144: loss: 0.030, val_loss:0.053 val_mae:0.053\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0299 - mae: 0.0299 - val_loss: 0.0525 - val_mae: 0.0525\n",
      "Epoch 146/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0297 - mae: 0.0297epoch 145: loss: 0.031, val_loss:0.066 val_mae:0.066\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0313 - mae: 0.0313 - val_loss: 0.0659 - val_mae: 0.0659\n",
      "Epoch 147/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0373 - mae: 0.0373epoch 146: loss: 0.036, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0358 - mae: 0.0358 - val_loss: 0.0586 - val_mae: 0.0586\n",
      "Epoch 148/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0352 - mae: 0.0352epoch 147: loss: 0.034, val_loss:0.058 val_mae:0.058\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0336 - mae: 0.0336 - val_loss: 0.0576 - val_mae: 0.0576\n",
      "Epoch 149/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0332 - mae: 0.0332epoch 148: loss: 0.034, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0337 - mae: 0.0337 - val_loss: 0.0590 - val_mae: 0.0590\n",
      "Epoch 150/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0364 - mae: 0.0364epoch 149: loss: 0.034, val_loss:0.058 val_mae:0.058\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0343 - mae: 0.0343 - val_loss: 0.0578 - val_mae: 0.0578\n",
      "Epoch 151/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0310 - mae: 0.0310epoch 150: loss: 0.030, val_loss:0.061 val_mae:0.061\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0305 - mae: 0.0305 - val_loss: 0.0611 - val_mae: 0.0611\n",
      "Epoch 152/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0319 - mae: 0.0319epoch 151: loss: 0.031, val_loss:0.057 val_mae:0.057\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0310 - mae: 0.0310 - val_loss: 0.0571 - val_mae: 0.0571\n",
      "Epoch 153/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0300 - mae: 0.0300epoch 152: loss: 0.030, val_loss:0.056 val_mae:0.056\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0300 - mae: 0.0300 - val_loss: 0.0560 - val_mae: 0.0560\n",
      "Epoch 154/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0301 - mae: 0.0301epoch 153: loss: 0.030, val_loss:0.054 val_mae:0.054\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0296 - mae: 0.0296 - val_loss: 0.0544 - val_mae: 0.0544\n",
      "Epoch 155/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0285 - mae: 0.0285epoch 154: loss: 0.031, val_loss:0.076 val_mae:0.076\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0305 - mae: 0.0305 - val_loss: 0.0759 - val_mae: 0.0759\n",
      "Epoch 156/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0346 - mae: 0.0346epoch 155: loss: 0.033, val_loss:0.061 val_mae:0.061\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0332 - mae: 0.0332 - val_loss: 0.0608 - val_mae: 0.0608\n",
      "Epoch 157/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0341 - mae: 0.0341epoch 156: loss: 0.034, val_loss:0.058 val_mae:0.058\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0342 - mae: 0.0342 - val_loss: 0.0585 - val_mae: 0.0585\n",
      "Epoch 158/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0297 - mae: 0.0297epoch 157: loss: 0.029, val_loss:0.066 val_mae:0.066\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0293 - mae: 0.0293 - val_loss: 0.0656 - val_mae: 0.0656\n",
      "Epoch 159/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0315 - mae: 0.0315epoch 158: loss: 0.031, val_loss:0.057 val_mae:0.057\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0306 - mae: 0.0306 - val_loss: 0.0572 - val_mae: 0.0572\n",
      "Epoch 160/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0301 - mae: 0.0301epoch 159: loss: 0.032, val_loss:0.063 val_mae:0.063\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0320 - mae: 0.0320 - val_loss: 0.0629 - val_mae: 0.0629\n",
      "Epoch 161/300\n",
      "41/57 [====================>.........] - ETA: 0s - loss: 0.0405 - mae: 0.0405epoch 160: loss: 0.039, val_loss:0.064 val_mae:0.064\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0392 - mae: 0.0392 - val_loss: 0.0637 - val_mae: 0.0637\n",
      "Epoch 162/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0294 - mae: 0.0294epoch 161: loss: 0.030, val_loss:0.056 val_mae:0.056\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0296 - mae: 0.0296 - val_loss: 0.0559 - val_mae: 0.0559\n",
      "Epoch 163/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0293 - mae: 0.0293epoch 162: loss: 0.029, val_loss:0.053 val_mae:0.053\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0291 - mae: 0.0291 - val_loss: 0.0529 - val_mae: 0.0529\n",
      "Epoch 164/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0283 - mae: 0.0283epoch 163: loss: 0.030, val_loss:0.060 val_mae:0.060\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0297 - mae: 0.0297 - val_loss: 0.0602 - val_mae: 0.0602\n",
      "Epoch 165/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0311 - mae: 0.0311epoch 164: loss: 0.032, val_loss:0.058 val_mae:0.058\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0316 - mae: 0.0316 - val_loss: 0.0584 - val_mae: 0.0584\n",
      "Epoch 166/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0332 - mae: 0.0332epoch 165: loss: 0.033, val_loss:0.054 val_mae:0.054\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0331 - mae: 0.0331 - val_loss: 0.0543 - val_mae: 0.0543\n",
      "Epoch 167/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0348 - mae: 0.0348epoch 166: loss: 0.034, val_loss:0.063 val_mae:0.063\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0344 - mae: 0.0344 - val_loss: 0.0632 - val_mae: 0.0632\n",
      "Epoch 168/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0300 - mae: 0.0300epoch 167: loss: 0.030, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0295 - mae: 0.0295 - val_loss: 0.0593 - val_mae: 0.0593\n",
      "Epoch 169/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0288 - mae: 0.0288epoch 168: loss: 0.030, val_loss:0.061 val_mae:0.061\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0302 - mae: 0.0302 - val_loss: 0.0605 - val_mae: 0.0605\n",
      "Epoch 170/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0303 - mae: 0.0303epoch 169: loss: 0.031, val_loss:0.064 val_mae:0.064\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0305 - mae: 0.0305 - val_loss: 0.0637 - val_mae: 0.0637\n",
      "Epoch 171/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0307 - mae: 0.0307epoch 170: loss: 0.031, val_loss:0.058 val_mae:0.058\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0314 - mae: 0.0314 - val_loss: 0.0577 - val_mae: 0.0577\n",
      "Epoch 172/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0348 - mae: 0.0348epoch 171: loss: 0.037, val_loss:0.077 val_mae:0.077\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0366 - mae: 0.0366 - val_loss: 0.0773 - val_mae: 0.0773\n",
      "Epoch 173/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0360 - mae: 0.0360epoch 172: loss: 0.034, val_loss:0.056 val_mae:0.056\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0340 - mae: 0.0340 - val_loss: 0.0561 - val_mae: 0.0561\n",
      "Epoch 174/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0292 - mae: 0.0292epoch 173: loss: 0.028, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0284 - mae: 0.0284 - val_loss: 0.0589 - val_mae: 0.0589\n",
      "Epoch 175/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0276 - mae: 0.0276epoch 174: loss: 0.028, val_loss:0.057 val_mae:0.057\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0281 - mae: 0.0281 - val_loss: 0.0567 - val_mae: 0.0567\n",
      "Epoch 176/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0297 - mae: 0.0297epoch 175: loss: 0.030, val_loss:0.056 val_mae:0.056\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0297 - mae: 0.0297 - val_loss: 0.0562 - val_mae: 0.0562\n",
      "Epoch 177/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0292 - mae: 0.0292epoch 176: loss: 0.030, val_loss:0.061 val_mae:0.061\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0295 - mae: 0.0295 - val_loss: 0.0614 - val_mae: 0.0614\n",
      "Epoch 178/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0299 - mae: 0.0299epoch 177: loss: 0.030, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0303 - mae: 0.0303 - val_loss: 0.0549 - val_mae: 0.0549\n",
      "Epoch 179/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0279 - mae: 0.0279epoch 178: loss: 0.028, val_loss:0.058 val_mae:0.058\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0284 - mae: 0.0284 - val_loss: 0.0582 - val_mae: 0.0582\n",
      "Epoch 180/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0289 - mae: 0.0289epoch 179: loss: 0.029, val_loss:0.053 val_mae:0.053\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0285 - mae: 0.0285 - val_loss: 0.0528 - val_mae: 0.0528\n",
      "Epoch 181/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0286 - mae: 0.0286epoch 180: loss: 0.029, val_loss:0.060 val_mae:0.060\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0287 - mae: 0.0287 - val_loss: 0.0599 - val_mae: 0.0599\n",
      "Epoch 182/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0341 - mae: 0.0341epoch 181: loss: 0.033, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0331 - mae: 0.0331 - val_loss: 0.0554 - val_mae: 0.0554\n",
      "Epoch 183/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0277 - mae: 0.0277epoch 182: loss: 0.028, val_loss:0.060 val_mae:0.060\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0275 - mae: 0.0275 - val_loss: 0.0600 - val_mae: 0.0600\n",
      "Epoch 184/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0256 - mae: 0.0256epoch 183: loss: 0.025, val_loss:0.056 val_mae:0.056\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0255 - mae: 0.0255 - val_loss: 0.0556 - val_mae: 0.0556\n",
      "Epoch 185/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0268 - mae: 0.0268epoch 184: loss: 0.027, val_loss:0.053 val_mae:0.053\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0267 - mae: 0.0267 - val_loss: 0.0534 - val_mae: 0.0534\n",
      "Epoch 186/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0266 - mae: 0.0266epoch 185: loss: 0.026, val_loss:0.056 val_mae:0.056\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0261 - mae: 0.0261 - val_loss: 0.0563 - val_mae: 0.0563\n",
      "Epoch 187/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0275 - mae: 0.0275epoch 186: loss: 0.029, val_loss:0.057 val_mae:0.057\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0287 - mae: 0.0287 - val_loss: 0.0572 - val_mae: 0.0572\n",
      "Epoch 188/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0342 - mae: 0.0342epoch 187: loss: 0.032, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0324 - mae: 0.0324 - val_loss: 0.0553 - val_mae: 0.0553\n",
      "Epoch 189/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0291 - mae: 0.0291epoch 188: loss: 0.030, val_loss:0.056 val_mae:0.056\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0300 - mae: 0.0300 - val_loss: 0.0564 - val_mae: 0.0564\n",
      "Epoch 190/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0273 - mae: 0.0273epoch 189: loss: 0.028, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0281 - mae: 0.0281 - val_loss: 0.0551 - val_mae: 0.0551\n",
      "Epoch 191/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0268 - mae: 0.0268epoch 190: loss: 0.027, val_loss:0.064 val_mae:0.064\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0275 - mae: 0.0275 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 192/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0286 - mae: 0.0286epoch 191: loss: 0.028, val_loss:0.053 val_mae:0.053\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0284 - mae: 0.0284 - val_loss: 0.0527 - val_mae: 0.0527\n",
      "Epoch 193/300\n",
      "41/57 [====================>.........] - ETA: 0s - loss: 0.0323 - mae: 0.0323epoch 192: loss: 0.031, val_loss:0.058 val_mae:0.058\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0315 - mae: 0.0315 - val_loss: 0.0576 - val_mae: 0.0576\n",
      "Epoch 194/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0291 - mae: 0.0291epoch 193: loss: 0.029, val_loss:0.056 val_mae:0.056\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0295 - mae: 0.0295 - val_loss: 0.0564 - val_mae: 0.0564\n",
      "Epoch 195/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0276 - mae: 0.0276epoch 194: loss: 0.028, val_loss:0.058 val_mae:0.058\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0280 - mae: 0.0280 - val_loss: 0.0583 - val_mae: 0.0583\n",
      "Epoch 196/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0279 - mae: 0.0279epoch 195: loss: 0.028, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0277 - mae: 0.0277 - val_loss: 0.0591 - val_mae: 0.0591\n",
      "Epoch 197/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0256 - mae: 0.0256epoch 196: loss: 0.025, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0247 - mae: 0.0247 - val_loss: 0.0552 - val_mae: 0.0552\n",
      "Epoch 198/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0289 - mae: 0.0289epoch 197: loss: 0.029, val_loss:0.053 val_mae:0.053\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0290 - mae: 0.0290 - val_loss: 0.0534 - val_mae: 0.0534\n",
      "Epoch 199/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0285 - mae: 0.0285epoch 198: loss: 0.029, val_loss:0.066 val_mae:0.066\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0293 - mae: 0.0293 - val_loss: 0.0655 - val_mae: 0.0655\n",
      "Epoch 200/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0286 - mae: 0.0286epoch 199: loss: 0.028, val_loss:0.060 val_mae:0.060\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0283 - mae: 0.0283 - val_loss: 0.0605 - val_mae: 0.0605\n",
      "Epoch 201/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0270 - mae: 0.0270epoch 200: loss: 0.026, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0261 - mae: 0.0261 - val_loss: 0.0593 - val_mae: 0.0593\n",
      "Epoch 202/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0294 - mae: 0.0294epoch 201: loss: 0.029, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0293 - mae: 0.0293 - val_loss: 0.0550 - val_mae: 0.0550\n",
      "Epoch 203/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0324 - mae: 0.0324epoch 202: loss: 0.032, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0322 - mae: 0.0322 - val_loss: 0.0550 - val_mae: 0.0550\n",
      "Epoch 204/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0301 - mae: 0.0301epoch 203: loss: 0.030, val_loss:0.072 val_mae:0.072\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0301 - mae: 0.0301 - val_loss: 0.0717 - val_mae: 0.0717\n",
      "Epoch 205/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0348 - mae: 0.0348epoch 204: loss: 0.033, val_loss:0.064 val_mae:0.064\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0335 - mae: 0.0335 - val_loss: 0.0641 - val_mae: 0.0641\n",
      "Epoch 206/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0298 - mae: 0.0298epoch 205: loss: 0.029, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0293 - mae: 0.0293 - val_loss: 0.0547 - val_mae: 0.0547\n",
      "Epoch 207/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0247 - mae: 0.0247epoch 206: loss: 0.026, val_loss:0.054 val_mae:0.054\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0255 - mae: 0.0255 - val_loss: 0.0536 - val_mae: 0.0536\n",
      "Epoch 208/300\n",
      "41/57 [====================>.........] - ETA: 0s - loss: 0.0289 - mae: 0.0289epoch 207: loss: 0.028, val_loss:0.054 val_mae:0.054\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0284 - mae: 0.0284 - val_loss: 0.0537 - val_mae: 0.0537\n",
      "Epoch 209/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0271 - mae: 0.0271epoch 208: loss: 0.026, val_loss:0.058 val_mae:0.058\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0259 - mae: 0.0259 - val_loss: 0.0577 - val_mae: 0.0577\n",
      "Epoch 210/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0264 - mae: 0.0264epoch 209: loss: 0.026, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0261 - mae: 0.0261 - val_loss: 0.0591 - val_mae: 0.0591\n",
      "Epoch 211/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0270 - mae: 0.0270epoch 210: loss: 0.028, val_loss:0.060 val_mae:0.060\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0276 - mae: 0.0276 - val_loss: 0.0603 - val_mae: 0.0603\n",
      "Epoch 212/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0270 - mae: 0.0270epoch 211: loss: 0.028, val_loss:0.062 val_mae:0.062\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0284 - mae: 0.0284 - val_loss: 0.0623 - val_mae: 0.0623\n",
      "Epoch 213/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0323 - mae: 0.0323epoch 212: loss: 0.032, val_loss:0.064 val_mae:0.064\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0322 - mae: 0.0322 - val_loss: 0.0635 - val_mae: 0.0635\n",
      "Epoch 214/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0272 - mae: 0.0272epoch 213: loss: 0.028, val_loss:0.061 val_mae:0.061\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0275 - mae: 0.0275 - val_loss: 0.0608 - val_mae: 0.0608\n",
      "Epoch 215/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0285 - mae: 0.0285epoch 214: loss: 0.028, val_loss:0.057 val_mae:0.057\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0278 - mae: 0.0278 - val_loss: 0.0565 - val_mae: 0.0565\n",
      "Epoch 216/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0253 - mae: 0.0253epoch 215: loss: 0.025, val_loss:0.056 val_mae:0.056\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0245 - mae: 0.0245 - val_loss: 0.0557 - val_mae: 0.0557\n",
      "Epoch 217/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0255 - mae: 0.0255epoch 216: loss: 0.025, val_loss:0.056 val_mae:0.056\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0252 - mae: 0.0252 - val_loss: 0.0558 - val_mae: 0.0558\n",
      "Epoch 218/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0260 - mae: 0.0260epoch 217: loss: 0.027, val_loss:0.061 val_mae:0.061\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0266 - mae: 0.0266 - val_loss: 0.0610 - val_mae: 0.0610\n",
      "Epoch 219/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0259 - mae: 0.0259epoch 218: loss: 0.026, val_loss:0.054 val_mae:0.054\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0258 - mae: 0.0258 - val_loss: 0.0540 - val_mae: 0.0540\n",
      "Epoch 220/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0246 - mae: 0.0246epoch 219: loss: 0.025, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0246 - mae: 0.0246 - val_loss: 0.0547 - val_mae: 0.0547\n",
      "Epoch 221/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0254 - mae: 0.0254epoch 220: loss: 0.026, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0261 - mae: 0.0261 - val_loss: 0.0586 - val_mae: 0.0586\n",
      "Epoch 222/300\n",
      "41/57 [====================>.........] - ETA: 0s - loss: 0.0241 - mae: 0.0241epoch 221: loss: 0.025, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0255 - mae: 0.0255 - val_loss: 0.0551 - val_mae: 0.0551\n",
      "Epoch 223/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0284 - mae: 0.0284epoch 222: loss: 0.027, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0274 - mae: 0.0274 - val_loss: 0.0548 - val_mae: 0.0548\n",
      "Epoch 224/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0253 - mae: 0.0253epoch 223: loss: 0.025, val_loss:0.058 val_mae:0.058\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0249 - mae: 0.0249 - val_loss: 0.0582 - val_mae: 0.0582\n",
      "Epoch 225/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0296 - mae: 0.0296epoch 224: loss: 0.029, val_loss:0.068 val_mae:0.068\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0293 - mae: 0.0293 - val_loss: 0.0678 - val_mae: 0.0678\n",
      "Epoch 226/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0311 - mae: 0.0311epoch 225: loss: 0.029, val_loss:0.057 val_mae:0.057\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0293 - mae: 0.0293 - val_loss: 0.0570 - val_mae: 0.0570\n",
      "Epoch 227/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0268 - mae: 0.0268epoch 226: loss: 0.026, val_loss:0.053 val_mae:0.053\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0259 - mae: 0.0259 - val_loss: 0.0534 - val_mae: 0.0534\n",
      "Epoch 228/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0276 - mae: 0.0276epoch 227: loss: 0.027, val_loss:0.056 val_mae:0.056\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0272 - mae: 0.0272 - val_loss: 0.0555 - val_mae: 0.0555\n",
      "Epoch 229/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0288 - mae: 0.0288epoch 228: loss: 0.029, val_loss:0.057 val_mae:0.057\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0291 - mae: 0.0291 - val_loss: 0.0572 - val_mae: 0.0572\n",
      "Epoch 230/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0283 - mae: 0.0283epoch 229: loss: 0.028, val_loss:0.053 val_mae:0.053\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0282 - mae: 0.0282 - val_loss: 0.0532 - val_mae: 0.0532\n",
      "Epoch 231/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0281 - mae: 0.0281epoch 230: loss: 0.028, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0276 - mae: 0.0276 - val_loss: 0.0547 - val_mae: 0.0547\n",
      "Epoch 232/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0261 - mae: 0.0261epoch 231: loss: 0.026, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0258 - mae: 0.0258 - val_loss: 0.0551 - val_mae: 0.0551\n",
      "Epoch 233/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0254 - mae: 0.0254epoch 232: loss: 0.025, val_loss:0.053 val_mae:0.053\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0253 - mae: 0.0253 - val_loss: 0.0533 - val_mae: 0.0533\n",
      "Epoch 234/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0214 - mae: 0.0214epoch 233: loss: 0.022, val_loss:0.064 val_mae:0.064\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0220 - mae: 0.0220 - val_loss: 0.0640 - val_mae: 0.0640\n",
      "Epoch 235/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0250 - mae: 0.0250epoch 234: loss: 0.025, val_loss:0.067 val_mae:0.067\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0252 - mae: 0.0252 - val_loss: 0.0669 - val_mae: 0.0669\n",
      "Epoch 236/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0243 - mae: 0.0243epoch 235: loss: 0.024, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0245 - mae: 0.0245 - val_loss: 0.0548 - val_mae: 0.0548\n",
      "Epoch 237/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0286 - mae: 0.0286epoch 236: loss: 0.028, val_loss:0.052 val_mae:0.052\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0277 - mae: 0.0277 - val_loss: 0.0523 - val_mae: 0.0523\n",
      "Epoch 238/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0219 - mae: 0.0219epoch 237: loss: 0.024, val_loss:0.064 val_mae:0.064\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0240 - mae: 0.0240 - val_loss: 0.0638 - val_mae: 0.0638\n",
      "Epoch 239/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0273 - mae: 0.0273epoch 238: loss: 0.027, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0271 - mae: 0.0271 - val_loss: 0.0545 - val_mae: 0.0545\n",
      "Epoch 240/300\n",
      "41/57 [====================>.........] - ETA: 0s - loss: 0.0215 - mae: 0.0215epoch 239: loss: 0.021, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0214 - mae: 0.0214 - val_loss: 0.0594 - val_mae: 0.0594\n",
      "Epoch 241/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0236 - mae: 0.0236epoch 240: loss: 0.024, val_loss:0.060 val_mae:0.060\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0241 - mae: 0.0241 - val_loss: 0.0598 - val_mae: 0.0598\n",
      "Epoch 242/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0253 - mae: 0.0253epoch 241: loss: 0.025, val_loss:0.056 val_mae:0.056\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0254 - mae: 0.0254 - val_loss: 0.0561 - val_mae: 0.0561\n",
      "Epoch 243/300\n",
      "41/57 [====================>.........] - ETA: 0s - loss: 0.0244 - mae: 0.0244epoch 242: loss: 0.025, val_loss:0.062 val_mae:0.062\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0254 - mae: 0.0254 - val_loss: 0.0623 - val_mae: 0.0623\n",
      "Epoch 244/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0262 - mae: 0.0262epoch 243: loss: 0.026, val_loss:0.054 val_mae:0.054\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0261 - mae: 0.0261 - val_loss: 0.0539 - val_mae: 0.0539\n",
      "Epoch 245/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0227 - mae: 0.0227epoch 244: loss: 0.023, val_loss:0.054 val_mae:0.054\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0225 - mae: 0.0225 - val_loss: 0.0541 - val_mae: 0.0541\n",
      "Epoch 246/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0256 - mae: 0.0256epoch 245: loss: 0.026, val_loss:0.054 val_mae:0.054\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0256 - mae: 0.0256 - val_loss: 0.0543 - val_mae: 0.0543\n",
      "Epoch 247/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0283 - mae: 0.0283epoch 246: loss: 0.028, val_loss:0.054 val_mae:0.054\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0281 - mae: 0.0281 - val_loss: 0.0541 - val_mae: 0.0541\n",
      "Epoch 248/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0254 - mae: 0.0254epoch 247: loss: 0.024, val_loss:0.052 val_mae:0.052\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0245 - mae: 0.0245 - val_loss: 0.0516 - val_mae: 0.0516\n",
      "Epoch 249/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0266 - mae: 0.0266epoch 248: loss: 0.027, val_loss:0.053 val_mae:0.053\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0272 - mae: 0.0272 - val_loss: 0.0533 - val_mae: 0.0533\n",
      "Epoch 250/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0293 - mae: 0.0293epoch 249: loss: 0.028, val_loss:0.052 val_mae:0.052\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0283 - mae: 0.0283 - val_loss: 0.0521 - val_mae: 0.0521\n",
      "Epoch 251/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0234 - mae: 0.0234epoch 250: loss: 0.024, val_loss:0.053 val_mae:0.053\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.0242 - val_loss: 0.0527 - val_mae: 0.0527\n",
      "Epoch 252/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0223 - mae: 0.0223epoch 251: loss: 0.023, val_loss:0.057 val_mae:0.057\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0232 - mae: 0.0232 - val_loss: 0.0567 - val_mae: 0.0567\n",
      "Epoch 253/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0222 - mae: 0.0222epoch 252: loss: 0.023, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0229 - mae: 0.0229 - val_loss: 0.0592 - val_mae: 0.0592\n",
      "Epoch 254/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0252 - mae: 0.0252epoch 253: loss: 0.025, val_loss:0.054 val_mae:0.054\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0250 - mae: 0.0250 - val_loss: 0.0542 - val_mae: 0.0542\n",
      "Epoch 255/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0248 - mae: 0.0248epoch 254: loss: 0.025, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0253 - mae: 0.0253 - val_loss: 0.0555 - val_mae: 0.0555\n",
      "Epoch 256/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0248 - mae: 0.0248epoch 255: loss: 0.025, val_loss:0.053 val_mae:0.053\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0249 - mae: 0.0249 - val_loss: 0.0531 - val_mae: 0.0531\n",
      "Epoch 257/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0225 - mae: 0.0225epoch 256: loss: 0.023, val_loss:0.051 val_mae:0.051\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0229 - mae: 0.0229 - val_loss: 0.0508 - val_mae: 0.0508\n",
      "Epoch 258/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0211 - mae: 0.0211epoch 257: loss: 0.021, val_loss:0.052 val_mae:0.052\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0208 - mae: 0.0208 - val_loss: 0.0522 - val_mae: 0.0522\n",
      "Epoch 259/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0211 - mae: 0.0211epoch 258: loss: 0.021, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0213 - mae: 0.0213 - val_loss: 0.0546 - val_mae: 0.0546\n",
      "Epoch 260/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0212 - mae: 0.0212epoch 259: loss: 0.021, val_loss:0.057 val_mae:0.057\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0209 - mae: 0.0209 - val_loss: 0.0570 - val_mae: 0.0570\n",
      "Epoch 261/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0263 - mae: 0.0263epoch 260: loss: 0.025, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0250 - mae: 0.0250 - val_loss: 0.0548 - val_mae: 0.0548\n",
      "Epoch 262/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0206 - mae: 0.0206epoch 261: loss: 0.020, val_loss:0.060 val_mae:0.060\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0204 - mae: 0.0204 - val_loss: 0.0598 - val_mae: 0.0598\n",
      "Epoch 263/300\n",
      "41/57 [====================>.........] - ETA: 0s - loss: 0.0286 - mae: 0.0286epoch 262: loss: 0.028, val_loss:0.058 val_mae:0.058\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0277 - mae: 0.0277 - val_loss: 0.0581 - val_mae: 0.0581\n",
      "Epoch 264/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0284 - mae: 0.0284epoch 263: loss: 0.027, val_loss:0.054 val_mae:0.054\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0267 - mae: 0.0267 - val_loss: 0.0541 - val_mae: 0.0541\n",
      "Epoch 265/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0259 - mae: 0.0259epoch 264: loss: 0.026, val_loss:0.054 val_mae:0.054\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0263 - mae: 0.0263 - val_loss: 0.0543 - val_mae: 0.0543\n",
      "Epoch 266/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0218 - mae: 0.0218epoch 265: loss: 0.022, val_loss:0.054 val_mae:0.054\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0217 - mae: 0.0217 - val_loss: 0.0543 - val_mae: 0.0543\n",
      "Epoch 267/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0238 - mae: 0.0238epoch 266: loss: 0.024, val_loss:0.052 val_mae:0.052\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.0242 - val_loss: 0.0525 - val_mae: 0.0525\n",
      "Epoch 268/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0263 - mae: 0.0263epoch 267: loss: 0.027, val_loss:0.058 val_mae:0.058\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0270 - mae: 0.0270 - val_loss: 0.0582 - val_mae: 0.0582\n",
      "Epoch 269/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0227 - mae: 0.0227epoch 268: loss: 0.023, val_loss:0.061 val_mae:0.061\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0230 - mae: 0.0230 - val_loss: 0.0606 - val_mae: 0.0606\n",
      "Epoch 270/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0232 - mae: 0.0232epoch 269: loss: 0.023, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0229 - mae: 0.0229 - val_loss: 0.0594 - val_mae: 0.0594\n",
      "Epoch 271/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0238 - mae: 0.0238epoch 270: loss: 0.024, val_loss:0.064 val_mae:0.064\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0241 - mae: 0.0241 - val_loss: 0.0636 - val_mae: 0.0636\n",
      "Epoch 272/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0237 - mae: 0.0237epoch 271: loss: 0.023, val_loss:0.054 val_mae:0.054\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0231 - mae: 0.0231 - val_loss: 0.0543 - val_mae: 0.0543\n",
      "Epoch 273/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0218 - mae: 0.0218epoch 272: loss: 0.021, val_loss:0.052 val_mae:0.052\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0215 - mae: 0.0215 - val_loss: 0.0520 - val_mae: 0.0520\n",
      "Epoch 274/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0216 - mae: 0.0216epoch 273: loss: 0.022, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0218 - mae: 0.0218 - val_loss: 0.0588 - val_mae: 0.0588\n",
      "Epoch 275/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0239 - mae: 0.0239epoch 274: loss: 0.023, val_loss:0.054 val_mae:0.054\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0232 - mae: 0.0232 - val_loss: 0.0545 - val_mae: 0.0545\n",
      "Epoch 276/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0208 - mae: 0.0208epoch 275: loss: 0.022, val_loss:0.053 val_mae:0.053\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0219 - mae: 0.0219 - val_loss: 0.0529 - val_mae: 0.0529\n",
      "Epoch 277/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0210 - mae: 0.0210epoch 276: loss: 0.021, val_loss:0.057 val_mae:0.057\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0213 - mae: 0.0213 - val_loss: 0.0567 - val_mae: 0.0567\n",
      "Epoch 278/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0226 - mae: 0.0226epoch 277: loss: 0.023, val_loss:0.058 val_mae:0.058\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0230 - mae: 0.0230 - val_loss: 0.0581 - val_mae: 0.0581\n",
      "Epoch 279/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0234 - mae: 0.0234epoch 278: loss: 0.022, val_loss:0.054 val_mae:0.054\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0223 - mae: 0.0223 - val_loss: 0.0536 - val_mae: 0.0536\n",
      "Epoch 280/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0196 - mae: 0.0196epoch 279: loss: 0.019, val_loss:0.052 val_mae:0.052\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0193 - mae: 0.0193 - val_loss: 0.0524 - val_mae: 0.0524\n",
      "Epoch 281/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0242 - mae: 0.0242epoch 280: loss: 0.025, val_loss:0.062 val_mae:0.062\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0247 - mae: 0.0247 - val_loss: 0.0624 - val_mae: 0.0624\n",
      "Epoch 282/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0308 - mae: 0.0308epoch 281: loss: 0.030, val_loss:0.054 val_mae:0.054\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0301 - mae: 0.0301 - val_loss: 0.0540 - val_mae: 0.0540\n",
      "Epoch 283/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0216 - mae: 0.0216epoch 282: loss: 0.022, val_loss:0.057 val_mae:0.057\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0220 - mae: 0.0220 - val_loss: 0.0568 - val_mae: 0.0568\n",
      "Epoch 284/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0225 - mae: 0.0225epoch 283: loss: 0.023, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0227 - mae: 0.0227 - val_loss: 0.0551 - val_mae: 0.0551\n",
      "Epoch 285/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0226 - mae: 0.0226epoch 284: loss: 0.022, val_loss:0.053 val_mae:0.053\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0220 - mae: 0.0220 - val_loss: 0.0530 - val_mae: 0.0530\n",
      "Epoch 286/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0223 - mae: 0.0223epoch 285: loss: 0.023, val_loss:0.060 val_mae:0.060\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0227 - mae: 0.0227 - val_loss: 0.0595 - val_mae: 0.0595\n",
      "Epoch 287/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0225 - mae: 0.0225epoch 286: loss: 0.023, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0231 - mae: 0.0231 - val_loss: 0.0551 - val_mae: 0.0551\n",
      "Epoch 288/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0246 - mae: 0.0246epoch 287: loss: 0.024, val_loss:0.055 val_mae:0.055\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0239 - mae: 0.0239 - val_loss: 0.0554 - val_mae: 0.0554\n",
      "Epoch 289/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0230 - mae: 0.0230epoch 288: loss: 0.023, val_loss:0.052 val_mae:0.052\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0229 - mae: 0.0229 - val_loss: 0.0525 - val_mae: 0.0525\n",
      "Epoch 290/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0211 - mae: 0.0211epoch 289: loss: 0.021, val_loss:0.050 val_mae:0.050\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0209 - mae: 0.0209 - val_loss: 0.0505 - val_mae: 0.0505\n",
      "Epoch 291/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0201 - mae: 0.0201epoch 290: loss: 0.021, val_loss:0.051 val_mae:0.051\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0207 - mae: 0.0207 - val_loss: 0.0512 - val_mae: 0.0512\n",
      "Epoch 292/300\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.0215 - mae: 0.0215epoch 291: loss: 0.021, val_loss:0.052 val_mae:0.052\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0211 - mae: 0.0211 - val_loss: 0.0524 - val_mae: 0.0524\n",
      "Epoch 293/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0204 - mae: 0.0204epoch 292: loss: 0.020, val_loss:0.052 val_mae:0.052\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0525 - val_mae: 0.0525\n",
      "Epoch 294/300\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.0212 - mae: 0.0212epoch 293: loss: 0.022, val_loss:0.056 val_mae:0.056\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0224 - mae: 0.0224 - val_loss: 0.0559 - val_mae: 0.0559\n",
      "Epoch 295/300\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.0220 - mae: 0.0220epoch 294: loss: 0.021, val_loss:0.052 val_mae:0.052\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0214 - mae: 0.0214 - val_loss: 0.0524 - val_mae: 0.0524\n",
      "Epoch 296/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0231 - mae: 0.0231epoch 295: loss: 0.023, val_loss:0.052 val_mae:0.052\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0228 - mae: 0.0228 - val_loss: 0.0520 - val_mae: 0.0520\n",
      "Epoch 297/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0211 - mae: 0.0211epoch 296: loss: 0.022, val_loss:0.051 val_mae:0.051\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0222 - mae: 0.0222 - val_loss: 0.0514 - val_mae: 0.0514\n",
      "Epoch 298/300\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.0197 - mae: 0.0197epoch 297: loss: 0.022, val_loss:0.059 val_mae:0.059\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0218 - mae: 0.0218 - val_loss: 0.0594 - val_mae: 0.0594\n",
      "Epoch 299/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0242 - mae: 0.0242epoch 298: loss: 0.023, val_loss:0.053 val_mae:0.053\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0231 - mae: 0.0231 - val_loss: 0.0528 - val_mae: 0.0528\n",
      "Epoch 300/300\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.0202 - mae: 0.0202epoch 299: loss: 0.022, val_loss:0.057 val_mae:0.057\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.0216 - mae: 0.0216 - val_loss: 0.0567 - val_mae: 0.0567\n"
     ]
    }
   ],
   "source": [
    "#md.shuffle()\n",
    "model.fit(md,val_fraction=0.1, val_key='refractive_index', loss='mae', lr=0.001, epochs = 300, batch_size = 64, xscale='minmax',yscale=None, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Compiling model...\n",
      "INFO:root:Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 0.0011 - mae: 0.0270epoch 0: loss: 0.002, val_loss:0.010 val_mae:0.050\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0018 - mae: 0.0293 - val_loss: 0.0095 - val_mae: 0.0505\n",
      "Epoch 2/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 4.2293e-04 - mae: 0.0157epoch 1: loss: 0.001, val_loss:0.009 val_mae:0.050\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 6.9871e-04 - mae: 0.0145 - val_loss: 0.0091 - val_mae: 0.0503\n",
      "Epoch 3/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 3.4598e-04 - mae: 0.0123epoch 2: loss: 0.001, val_loss:0.009 val_mae:0.050\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.7062e-04 - mae: 0.0126 - val_loss: 0.0092 - val_mae: 0.0503\n",
      "Epoch 4/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 3.9102e-04 - mae: 0.0110epoch 3: loss: 0.001, val_loss:0.009 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.6609e-04 - mae: 0.0135 - val_loss: 0.0093 - val_mae: 0.0517\n",
      "Epoch 5/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.3980e-04 - mae: 0.0123epoch 4: loss: 0.001, val_loss:0.009 val_mae:0.050\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.0947e-04 - mae: 0.0118 - val_loss: 0.0093 - val_mae: 0.0505\n",
      "Epoch 6/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0171epoch 5: loss: 0.000, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.9527e-04 - mae: 0.0120 - val_loss: 0.0094 - val_mae: 0.0506\n",
      "Epoch 7/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.8389e-04 - mae: 0.0123epoch 6: loss: 0.000, val_loss:0.010 val_mae:0.053\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.5512e-04 - mae: 0.0109 - val_loss: 0.0098 - val_mae: 0.0532\n",
      "Epoch 8/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 3.4838e-04 - mae: 0.0142epoch 7: loss: 0.001, val_loss:0.009 val_mae:0.050\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.7610e-04 - mae: 0.0142 - val_loss: 0.0092 - val_mae: 0.0499\n",
      "Epoch 9/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 4.2091e-04 - mae: 0.0123epoch 8: loss: 0.001, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.5291e-04 - mae: 0.0131 - val_loss: 0.0098 - val_mae: 0.0514\n",
      "Epoch 10/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.5551e-04 - mae: 0.0122epoch 9: loss: 0.001, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.6515e-04 - mae: 0.0139 - val_loss: 0.0093 - val_mae: 0.0509\n",
      "Epoch 11/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0128epoch 10: loss: 0.000, val_loss:0.010 val_mae:0.050\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.8372e-04 - mae: 0.0122 - val_loss: 0.0095 - val_mae: 0.0501\n",
      "Epoch 12/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0147epoch 11: loss: 0.001, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.1137e-04 - mae: 0.0131 - val_loss: 0.0091 - val_mae: 0.0509\n",
      "Epoch 13/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.2365e-04 - mae: 0.0107epoch 12: loss: 0.000, val_loss:0.009 val_mae:0.050\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.6050e-04 - mae: 0.0119 - val_loss: 0.0091 - val_mae: 0.0500\n",
      "Epoch 14/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.0252e-04 - mae: 0.0097epoch 13: loss: 0.001, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.6375e-04 - mae: 0.0140 - val_loss: 0.0092 - val_mae: 0.0513\n",
      "Epoch 15/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.4898e-04 - mae: 0.0125epoch 14: loss: 0.001, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.0984e-04 - mae: 0.0131 - val_loss: 0.0094 - val_mae: 0.0507\n",
      "Epoch 16/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.1145e-04 - mae: 0.0103epoch 15: loss: 0.000, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.0780e-04 - mae: 0.0109 - val_loss: 0.0097 - val_mae: 0.0514\n",
      "Epoch 17/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.6838e-04 - mae: 0.0110epoch 16: loss: 0.000, val_loss:0.009 val_mae:0.050\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.8801e-04 - mae: 0.0137 - val_loss: 0.0094 - val_mae: 0.0503\n",
      "Epoch 18/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0137epoch 17: loss: 0.001, val_loss:0.010 val_mae:0.053\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.0025e-04 - mae: 0.0131 - val_loss: 0.0098 - val_mae: 0.0529\n",
      "Epoch 19/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 0.0012 - mae: 0.0204epoch 18: loss: 0.001, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 6.1675e-04 - mae: 0.0152 - val_loss: 0.0094 - val_mae: 0.0507\n",
      "Epoch 20/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 4.4805e-04 - mae: 0.0161epoch 19: loss: 0.001, val_loss:0.010 val_mae:0.058\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.8473e-04 - mae: 0.0148 - val_loss: 0.0102 - val_mae: 0.0580\n",
      "Epoch 21/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 8.4729e-04 - mae: 0.0236epoch 20: loss: 0.001, val_loss:0.010 val_mae:0.055\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0230 - val_loss: 0.0096 - val_mae: 0.0549\n",
      "Epoch 22/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 7.7041e-04 - mae: 0.0213epoch 21: loss: 0.001, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 6.8664e-04 - mae: 0.0165 - val_loss: 0.0100 - val_mae: 0.0511\n",
      "Epoch 23/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.2364e-04 - mae: 0.0112epoch 22: loss: 0.001, val_loss:0.010 val_mae:0.056\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 6.2281e-04 - mae: 0.0162 - val_loss: 0.0102 - val_mae: 0.0556\n",
      "Epoch 24/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 8.9509e-04 - mae: 0.0243epoch 23: loss: 0.001, val_loss:0.010 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 6.1376e-04 - mae: 0.0167 - val_loss: 0.0095 - val_mae: 0.0518\n",
      "Epoch 25/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.8678e-04 - mae: 0.0128epoch 24: loss: 0.000, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.6426e-04 - mae: 0.0111 - val_loss: 0.0092 - val_mae: 0.0510\n",
      "Epoch 26/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.5033e-04 - mae: 0.0107epoch 25: loss: 0.000, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.7319e-04 - mae: 0.0116 - val_loss: 0.0093 - val_mae: 0.0507\n",
      "Epoch 27/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 9.6387e-04 - mae: 0.0125epoch 26: loss: 0.000, val_loss:0.009 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.4608e-04 - mae: 0.0109 - val_loss: 0.0093 - val_mae: 0.0521\n",
      "Epoch 28/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0151epoch 27: loss: 0.000, val_loss:0.009 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.4063e-04 - mae: 0.0135 - val_loss: 0.0094 - val_mae: 0.0516\n",
      "Epoch 29/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.8061e-04 - mae: 0.0102epoch 28: loss: 0.000, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.6871e-04 - mae: 0.0114 - val_loss: 0.0095 - val_mae: 0.0508\n",
      "Epoch 30/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.6089e-04 - mae: 0.0110epoch 29: loss: 0.000, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.3813e-04 - mae: 0.0108 - val_loss: 0.0095 - val_mae: 0.0509\n",
      "Epoch 31/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.9423e-04 - mae: 0.0108epoch 30: loss: 0.000, val_loss:0.009 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.7099e-04 - mae: 0.0119 - val_loss: 0.0093 - val_mae: 0.0515\n",
      "Epoch 32/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.4781e-04 - mae: 0.0098epoch 31: loss: 0.000, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.0404e-04 - mae: 0.0103 - val_loss: 0.0097 - val_mae: 0.0515\n",
      "Epoch 33/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.3179e-04 - mae: 0.0120epoch 32: loss: 0.000, val_loss:0.010 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.3720e-04 - mae: 0.0115 - val_loss: 0.0096 - val_mae: 0.0521\n",
      "Epoch 34/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 3.2053e-04 - mae: 0.0124epoch 33: loss: 0.000, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.0966e-04 - mae: 0.0104 - val_loss: 0.0096 - val_mae: 0.0512\n",
      "Epoch 35/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.7297e-04 - mae: 0.0093epoch 34: loss: 0.000, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.5312e-04 - mae: 0.0134 - val_loss: 0.0096 - val_mae: 0.0507\n",
      "Epoch 36/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 5.0654e-04 - mae: 0.0121epoch 35: loss: 0.000, val_loss:0.009 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.2081e-04 - mae: 0.0128 - val_loss: 0.0094 - val_mae: 0.0520\n",
      "Epoch 37/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.6756e-04 - mae: 0.0126epoch 36: loss: 0.000, val_loss:0.010 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.3410e-04 - mae: 0.0110 - val_loss: 0.0096 - val_mae: 0.0516\n",
      "Epoch 38/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.6258e-04 - mae: 0.0097epoch 37: loss: 0.000, val_loss:0.010 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.8600e-04 - mae: 0.0122 - val_loss: 0.0096 - val_mae: 0.0517\n",
      "Epoch 39/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.6579e-04 - mae: 0.0103epoch 38: loss: 0.000, val_loss:0.009 val_mae:0.054\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.6172e-04 - mae: 0.0114 - val_loss: 0.0095 - val_mae: 0.0537\n",
      "Epoch 40/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0182epoch 39: loss: 0.001, val_loss:0.010 val_mae:0.053\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.5578e-04 - mae: 0.0149 - val_loss: 0.0098 - val_mae: 0.0528\n",
      "Epoch 41/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 0.0016 - mae: 0.0182epoch 40: loss: 0.001, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.3224e-04 - mae: 0.0146 - val_loss: 0.0096 - val_mae: 0.0508\n",
      "Epoch 42/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.8929e-04 - mae: 0.0124epoch 41: loss: 0.000, val_loss:0.010 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.9502e-04 - mae: 0.0132 - val_loss: 0.0100 - val_mae: 0.0516\n",
      "Epoch 43/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0162epoch 42: loss: 0.000, val_loss:0.010 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.1657e-04 - mae: 0.0136 - val_loss: 0.0098 - val_mae: 0.0520\n",
      "Epoch 44/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.9598e-04 - mae: 0.0094epoch 43: loss: 0.000, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.0053e-04 - mae: 0.0107 - val_loss: 0.0097 - val_mae: 0.0508\n",
      "Epoch 45/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 0.0010 - mae: 0.0153epoch 44: loss: 0.000, val_loss:0.009 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.3833e-04 - mae: 0.0123 - val_loss: 0.0095 - val_mae: 0.0516\n",
      "Epoch 46/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 6.5187e-04 - mae: 0.0139epoch 45: loss: 0.000, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.1389e-04 - mae: 0.0113 - val_loss: 0.0095 - val_mae: 0.0509\n",
      "Epoch 47/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.6198e-04 - mae: 0.0115epoch 46: loss: 0.000, val_loss:0.010 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8960e-04 - mae: 0.0105 - val_loss: 0.0098 - val_mae: 0.0520\n",
      "Epoch 48/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.6655e-04 - mae: 0.0102epoch 47: loss: 0.000, val_loss:0.009 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8963e-04 - mae: 0.0111 - val_loss: 0.0094 - val_mae: 0.0522\n",
      "Epoch 49/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.9727e-04 - mae: 0.0111epoch 48: loss: 0.000, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.6818e-04 - mae: 0.0106 - val_loss: 0.0093 - val_mae: 0.0513\n",
      "Epoch 50/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.1258e-04 - mae: 0.0083epoch 49: loss: 0.000, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.6143e-04 - mae: 0.0103 - val_loss: 0.0097 - val_mae: 0.0512\n",
      "Epoch 51/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.3335e-04 - mae: 0.0109epoch 50: loss: 0.000, val_loss:0.010 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.6225e-04 - mae: 0.0102 - val_loss: 0.0097 - val_mae: 0.0520\n",
      "Epoch 52/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.3817e-04 - mae: 0.0113epoch 51: loss: 0.000, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.5237e-04 - mae: 0.0127 - val_loss: 0.0093 - val_mae: 0.0508\n",
      "Epoch 53/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.4879e-04 - mae: 0.0117epoch 52: loss: 0.000, val_loss:0.010 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.4994e-04 - mae: 0.0101 - val_loss: 0.0097 - val_mae: 0.0520\n",
      "Epoch 54/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.3305e-04 - mae: 0.0113epoch 53: loss: 0.000, val_loss:0.010 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.6694e-04 - mae: 0.0104 - val_loss: 0.0097 - val_mae: 0.0520\n",
      "Epoch 55/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.4285e-04 - mae: 0.0092epoch 54: loss: 0.000, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.5914e-04 - mae: 0.0103 - val_loss: 0.0093 - val_mae: 0.0509\n",
      "Epoch 56/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.2419e-04 - mae: 0.0086epoch 55: loss: 0.000, val_loss:0.010 val_mae:0.053\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8410e-04 - mae: 0.0107 - val_loss: 0.0096 - val_mae: 0.0529\n",
      "Epoch 57/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.2561e-04 - mae: 0.0116epoch 56: loss: 0.000, val_loss:0.010 val_mae:0.053\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.9286e-04 - mae: 0.0132 - val_loss: 0.0097 - val_mae: 0.0528\n",
      "Epoch 58/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 4.2125e-04 - mae: 0.0161epoch 57: loss: 0.000, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.7955e-04 - mae: 0.0134 - val_loss: 0.0092 - val_mae: 0.0512\n",
      "Epoch 59/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.1389e-04 - mae: 0.0104epoch 58: loss: 0.000, val_loss:0.010 val_mae:0.053\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7594e-04 - mae: 0.0108 - val_loss: 0.0097 - val_mae: 0.0533\n",
      "Epoch 60/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 3.2474e-04 - mae: 0.0137epoch 59: loss: 0.000, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.7374e-04 - mae: 0.0134 - val_loss: 0.0091 - val_mae: 0.0511\n",
      "Epoch 61/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 6.5614e-04 - mae: 0.0132epoch 60: loss: 0.000, val_loss:0.010 val_mae:0.053\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.3596e-04 - mae: 0.0124 - val_loss: 0.0095 - val_mae: 0.0529\n",
      "Epoch 62/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.8969e-04 - mae: 0.0137epoch 61: loss: 0.000, val_loss:0.009 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8998e-04 - mae: 0.0111 - val_loss: 0.0094 - val_mae: 0.0525\n",
      "Epoch 63/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.6034e-04 - mae: 0.0121epoch 62: loss: 0.000, val_loss:0.010 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8545e-04 - mae: 0.0113 - val_loss: 0.0098 - val_mae: 0.0520\n",
      "Epoch 64/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.8201e-04 - mae: 0.0096epoch 63: loss: 0.000, val_loss:0.010 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.2107e-04 - mae: 0.0120 - val_loss: 0.0095 - val_mae: 0.0515\n",
      "Epoch 65/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.9990e-04 - mae: 0.0107epoch 64: loss: 0.000, val_loss:0.009 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.2544e-04 - mae: 0.0117 - val_loss: 0.0092 - val_mae: 0.0521\n",
      "Epoch 66/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 4.5045e-04 - mae: 0.0142epoch 65: loss: 0.000, val_loss:0.010 val_mae:0.054\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.2219e-04 - mae: 0.0137 - val_loss: 0.0104 - val_mae: 0.0541\n",
      "Epoch 67/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 3.4897e-04 - mae: 0.0134epoch 66: loss: 0.000, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9379e-04 - mae: 0.0116 - val_loss: 0.0095 - val_mae: 0.0513\n",
      "Epoch 68/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.1607e-04 - mae: 0.0113epoch 67: loss: 0.000, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9883e-04 - mae: 0.0121 - val_loss: 0.0097 - val_mae: 0.0511\n",
      "Epoch 69/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 4.9876e-04 - mae: 0.0138epoch 68: loss: 0.000, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.4748e-04 - mae: 0.0109 - val_loss: 0.0092 - val_mae: 0.0508\n",
      "Epoch 70/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.2962e-04 - mae: 0.0089epoch 69: loss: 0.000, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.3536e-04 - mae: 0.0103 - val_loss: 0.0095 - val_mae: 0.0509\n",
      "Epoch 71/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.0602e-04 - mae: 0.0105epoch 70: loss: 0.000, val_loss:0.009 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.5277e-04 - mae: 0.0108 - val_loss: 0.0093 - val_mae: 0.0519\n",
      "Epoch 72/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.6651e-04 - mae: 0.0094epoch 71: loss: 0.000, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.0162e-04 - mae: 0.0094 - val_loss: 0.0095 - val_mae: 0.0511\n",
      "Epoch 73/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.0006e-04 - mae: 0.0077epoch 72: loss: 0.000, val_loss:0.010 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.0275e-04 - mae: 0.0094 - val_loss: 0.0095 - val_mae: 0.0520\n",
      "Epoch 74/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.9072e-04 - mae: 0.0101epoch 73: loss: 0.000, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.9079e-04 - mae: 0.0093 - val_loss: 0.0095 - val_mae: 0.0508\n",
      "Epoch 75/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.7304e-04 - mae: 0.0100epoch 74: loss: 0.000, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.8449e-04 - mae: 0.0090 - val_loss: 0.0094 - val_mae: 0.0512\n",
      "Epoch 76/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.6417e-04 - mae: 0.0090epoch 75: loss: 0.000, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.9934e-04 - mae: 0.0094 - val_loss: 0.0092 - val_mae: 0.0511\n",
      "Epoch 77/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.7640e-04 - mae: 0.0098epoch 76: loss: 0.000, val_loss:0.009 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.2352e-04 - mae: 0.0104 - val_loss: 0.0095 - val_mae: 0.0521\n",
      "Epoch 78/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.6004e-04 - mae: 0.0120epoch 77: loss: 0.000, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.9087e-04 - mae: 0.0094 - val_loss: 0.0094 - val_mae: 0.0507\n",
      "Epoch 79/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 5.1177e-04 - mae: 0.0109epoch 78: loss: 0.000, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.2326e-04 - mae: 0.0101 - val_loss: 0.0097 - val_mae: 0.0507\n",
      "Epoch 80/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.2068e-04 - mae: 0.0097epoch 79: loss: 0.000, val_loss:0.010 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.4460e-04 - mae: 0.0105 - val_loss: 0.0096 - val_mae: 0.0519\n",
      "Epoch 81/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.5838e-04 - mae: 0.0099epoch 80: loss: 0.000, val_loss:0.010 val_mae:0.057\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.5869e-04 - mae: 0.0141 - val_loss: 0.0103 - val_mae: 0.0567\n",
      "Epoch 82/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 7.5091e-04 - mae: 0.0216epoch 81: loss: 0.001, val_loss:0.010 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.4578e-04 - mae: 0.0164 - val_loss: 0.0096 - val_mae: 0.0516\n",
      "Epoch 83/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 3.6681e-04 - mae: 0.0142epoch 82: loss: 0.000, val_loss:0.010 val_mae:0.057\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.7241e-04 - mae: 0.0153 - val_loss: 0.0103 - val_mae: 0.0567\n",
      "Epoch 84/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 5.5546e-04 - mae: 0.0205epoch 83: loss: 0.001, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.3904e-04 - mae: 0.0163 - val_loss: 0.0095 - val_mae: 0.0515\n",
      "Epoch 85/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 9.0688e-04 - mae: 0.0184epoch 84: loss: 0.000, val_loss:0.010 val_mae:0.053\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.7274e-04 - mae: 0.0130 - val_loss: 0.0100 - val_mae: 0.0530\n",
      "Epoch 86/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 3.8415e-04 - mae: 0.0157epoch 85: loss: 0.000, val_loss:0.010 val_mae:0.052\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.5522e-04 - mae: 0.0153 - val_loss: 0.0100 - val_mae: 0.0515\n",
      "Epoch 87/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 6.5558e-04 - mae: 0.0139epoch 86: loss: 0.000, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8282e-04 - mae: 0.0115 - val_loss: 0.0096 - val_mae: 0.0507\n",
      "Epoch 88/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.2386e-04 - mae: 0.0088epoch 87: loss: 0.000, val_loss:0.009 val_mae:0.050\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.0087e-04 - mae: 0.0101 - val_loss: 0.0094 - val_mae: 0.0503\n",
      "Epoch 89/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 8.3486e-05 - mae: 0.0066epoch 88: loss: 0.000, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.7802e-04 - mae: 0.0093 - val_loss: 0.0098 - val_mae: 0.0511\n",
      "Epoch 90/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.2205e-04 - mae: 0.0083epoch 89: loss: 0.000, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.5105e-04 - mae: 0.0084 - val_loss: 0.0095 - val_mae: 0.0510\n",
      "Epoch 91/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.1719e-04 - mae: 0.0086epoch 90: loss: 0.000, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.8085e-04 - mae: 0.0094 - val_loss: 0.0093 - val_mae: 0.0512\n",
      "Epoch 92/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 3.2617e-04 - mae: 0.0096epoch 91: loss: 0.001, val_loss:0.009 val_mae:0.053\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.4463e-04 - mae: 0.0156 - val_loss: 0.0094 - val_mae: 0.0528\n",
      "Epoch 93/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 3.4550e-04 - mae: 0.0141epoch 92: loss: 0.000, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.3336e-04 - mae: 0.0129 - val_loss: 0.0093 - val_mae: 0.0513\n",
      "Epoch 94/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.8600e-04 - mae: 0.0125epoch 93: loss: 0.000, val_loss:0.010 val_mae:0.053\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.9802e-04 - mae: 0.0161 - val_loss: 0.0097 - val_mae: 0.0528\n",
      "Epoch 95/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 4.8060e-04 - mae: 0.0145epoch 94: loss: 0.000, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.2077e-04 - mae: 0.0130 - val_loss: 0.0095 - val_mae: 0.0513\n",
      "Epoch 96/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 2.8333e-04 - mae: 0.0120epoch 95: loss: 0.000, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.8914e-04 - mae: 0.0096 - val_loss: 0.0095 - val_mae: 0.0511\n",
      "Epoch 97/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.2910e-04 - mae: 0.0085epoch 96: loss: 0.000, val_loss:0.009 val_mae:0.050\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.7548e-04 - mae: 0.0092 - val_loss: 0.0092 - val_mae: 0.0504\n",
      "Epoch 98/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 9.3943e-05 - mae: 0.0075epoch 97: loss: 0.000, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.6663e-04 - mae: 0.0092 - val_loss: 0.0094 - val_mae: 0.0514\n",
      "Epoch 99/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 3.0676e-04 - mae: 0.0112epoch 98: loss: 0.000, val_loss:0.010 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.7511e-04 - mae: 0.0093 - val_loss: 0.0095 - val_mae: 0.0506\n",
      "Epoch 100/100\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 1.0778e-04 - mae: 0.0081epoch 99: loss: 0.000, val_loss:0.009 val_mae:0.051\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.5412e-04 - mae: 0.0089 - val_loss: 0.0091 - val_mae: 0.0507\n"
     ]
    }
   ],
   "source": [
    "model.fit(md,val_fraction=0.1, val_key='refractive_index', lr=0.0005, epochs = 100, batch_size = 128, xscale='minmax',yscale=None, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saving model...\n",
      "INFO:root:Saved model to out/MODNet_refractive_index(.json/.h5/.pkl)\n"
     ]
    }
   ],
   "source": [
    "model.save('out/MODNet_refractive_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predicting on unseen data\n",
    "\n",
    "See \"predicting_ref_index\" notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:modnet]",
   "language": "python",
   "name": "conda-env-modnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
